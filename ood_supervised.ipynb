{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45899/outputs/ECAResNet50D_P_9c67f710.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\ECAResNet50D_P_9c67f710.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "ecaresnet50t\n",
      "80.326\n",
      "Accuracy: 80.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45402/outputs/ECAResNet101D_281c5844.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\ECAResNet101D_281c5844.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45610/outputs/ECAResNet101D_P_75a3370e.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\ECAResNet101D_P_75a3370e.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "ecaresnet269d\n",
      "83.258\n",
      "Accuracy: 83.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45402/outputs/ECAResNetLight_4f34b35b.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\ECAResNetLight_4f34b35b.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "efficientnet_b0\n",
      "77.286\n",
      "Accuracy: 77.29%\n",
      "efficientnet_b1\n",
      "77.346\n",
      "Accuracy: 77.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45403/outputs/effnetb1_pruned_9ebb3fe6.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\effnetb1_pruned_9ebb3fe6.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "efficientnet_b2\n",
      "77.732\n",
      "Accuracy: 77.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45403/outputs/effnetb2_pruned_203f55bc.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\effnetb2_pruned_203f55bc.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "efficientnet_b3\n",
      "78.14\n",
      "Accuracy: 78.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://imvl-automl-sh.oss-cn-shanghai.aliyuncs.com/darts/hyperml/hyperml/job_45403/outputs/effnetb3_pruned_5abcc29f.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\effnetb3_pruned_5abcc29f.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "efficientnet_b4\n",
      "78.696\n",
      "Accuracy: 78.70%\n",
      "efficientnet_el\n",
      "78.526\n",
      "Accuracy: 78.53%\n",
      "efficientnet_el_pruned\n",
      "77.362\n",
      "Accuracy: 77.36%\n",
      "efficientnet_em\n",
      "78.586\n",
      "Accuracy: 78.59%\n",
      "efficientnet_es\n",
      "78.002\n",
      "Accuracy: 78.00%\n",
      "efficientnet_es_pruned\n",
      "74.662\n",
      "Accuracy: 74.66%\n",
      "efficientnet_lite0\n",
      "74.984\n",
      "Accuracy: 74.98%\n",
      "efficientnetv2_rw_s\n",
      "80.84\n",
      "Accuracy: 80.84%\n",
      "ens_adv_inception_resnet_v2\n",
      "70.912\n",
      "Accuracy: 70.91%\n",
      "ese_vovnet19b_dw\n",
      "76.562\n",
      "Accuracy: 76.56%\n",
      "ese_vovnet39b\n",
      "79.12\n",
      "Accuracy: 79.12%\n",
      "fbnetc_100\n",
      "74.788\n",
      "Accuracy: 74.79%\n",
      "gernet_l\n",
      "80.306\n",
      "Accuracy: 80.31%\n",
      "gernet_m\n",
      "80.724\n",
      "Accuracy: 80.72%\n",
      "gernet_s\n",
      "76.722\n",
      "Accuracy: 76.72%\n",
      "ghostnet_100\n",
      "73.396\n",
      "Accuracy: 73.40%\n",
      "gluon_inception_v3\n",
      "72.96\n",
      "Accuracy: 72.96%\n",
      "gluon_resnet18_v1b\n",
      "69.842\n",
      "Accuracy: 69.84%\n",
      "gluon_resnet34_v1b\n",
      "73.606\n",
      "Accuracy: 73.61%\n",
      "gluon_resnet50_v1b\n",
      "77.074\n",
      "Accuracy: 77.07%\n",
      "gluon_resnet50_v1c\n",
      "77.406\n",
      "Accuracy: 77.41%\n",
      "gluon_resnet50_v1d\n",
      "78.644\n",
      "Accuracy: 78.64%\n",
      "gluon_resnet50_v1s\n",
      "78.312\n",
      "Accuracy: 78.31%\n",
      "gluon_resnet101_v1b\n",
      "78.564\n",
      "Accuracy: 78.56%\n",
      "gluon_resnet101_v1c\n",
      "78.894\n",
      "Accuracy: 78.89%\n",
      "gluon_resnet101_v1d\n",
      "80.058\n",
      "Accuracy: 80.06%\n",
      "gluon_resnet101_v1s\n",
      "79.892\n",
      "Accuracy: 79.89%\n",
      "gluon_resnet152_v1b\n",
      "79.072\n",
      "Accuracy: 79.07%\n",
      "gluon_resnet152_v1c\n",
      "79.48\n",
      "Accuracy: 79.48%\n",
      "gluon_resnet152_v1d\n",
      "80.34\n",
      "Accuracy: 80.34%\n",
      "gluon_resnet152_v1s\n",
      "80.656\n",
      "Accuracy: 80.66%\n",
      "gluon_resnext50_32x4d\n",
      "78.824\n",
      "Accuracy: 78.82%\n",
      "gluon_resnext101_32x4d\n",
      "79.696\n",
      "Accuracy: 79.70%\n",
      "gluon_resnext101_64x4d\n",
      "80.258\n",
      "Accuracy: 80.26%\n",
      "gluon_senet154\n",
      "81.24\n",
      "Accuracy: 81.24%\n",
      "gluon_seresnext50_32x4d\n",
      "79.58\n",
      "Accuracy: 79.58%\n",
      "gluon_seresnext101_32x4d\n",
      "80.546\n",
      "Accuracy: 80.55%\n",
      "gluon_seresnext101_64x4d\n",
      "80.508\n",
      "Accuracy: 80.51%\n",
      "gluon_xception65\n",
      "76.236\n",
      "Accuracy: 76.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_A_Green_38ms_75.9_23474aeb.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_A_Green_38ms_75.9_23474aeb.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_B_Green_40ms_76.5_1f882d1e.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_B_Green_40ms_76.5_1f882d1e.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_C_Green_44ms_77.1_d4148c9e.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_C_Green_44ms_77.1_d4148c9e.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_D_Green_50ms_77.4_23e3cdde.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_D_Green_50ms_77.4_23e3cdde.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_E_Green_55ms_77.9_90f20e8a.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_E_Green_55ms_77.9_90f20e8a.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://miil-public-eu.oss-eu-central-1.aliyuncs.com/public/HardCoReNAS/HardCoreNAS_F_Green_60ms_78.1_2855edf1.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\HardCoreNAS_F_Green_60ms_78.1_2855edf1.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 403: Forbidden\n",
      "hrnet_w18\n",
      "76.5\n",
      "Accuracy: 76.50%\n",
      "hrnet_w18_small\n",
      "71.852\n",
      "Accuracy: 71.85%\n",
      "hrnet_w18_small_v2\n",
      "74.774\n",
      "Accuracy: 74.77%\n",
      "hrnet_w30\n",
      "78.052\n",
      "Accuracy: 78.05%\n",
      "hrnet_w32\n",
      "78.23\n",
      "Accuracy: 78.23%\n",
      "hrnet_w40\n",
      "78.826\n",
      "Accuracy: 78.83%\n",
      "hrnet_w44\n",
      "78.772\n",
      "Accuracy: 78.77%\n",
      "hrnet_w48\n",
      "78.962\n",
      "Accuracy: 78.96%\n",
      "hrnet_w64\n",
      "79.356\n",
      "Accuracy: 79.36%\n",
      "ig_resnext101_32x8d\n",
      "82.852\n",
      "Accuracy: 82.85%\n",
      "ig_resnext101_32x16d\n",
      "84.528\n",
      "Accuracy: 84.53%\n",
      "ig_resnext101_32x32d\n",
      "85.334\n",
      "Accuracy: 85.33%\n",
      "ig_resnext101_32x48d\n",
      "85.58\n",
      "Accuracy: 85.58%\n",
      "inception_resnet_v2\n",
      "70.378\n",
      "Accuracy: 70.38%\n",
      "inception_v3\n",
      "69.62\n",
      "Accuracy: 69.62%\n",
      "inception_v4\n",
      "71.282\n",
      "Accuracy: 71.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\senet154-c7b49a05.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n",
      "legacy_seresnet18\n",
      "70.988\n",
      "Accuracy: 70.99%\n",
      "legacy_seresnet34\n",
      "74.504\n",
      "Accuracy: 74.50%\n",
      "legacy_seresnet50\n",
      "77.386\n",
      "Accuracy: 77.39%\n",
      "legacy_seresnet101\n",
      "77.972\n",
      "Accuracy: 77.97%\n",
      "legacy_seresnet152\n",
      "78.404\n",
      "Accuracy: 78.40%\n",
      "legacy_seresnext26_32x4d\n",
      "76.59\n",
      "Accuracy: 76.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\se_resnext50_32x4d-a260b3a4.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\se_resnext101_32x4d-3b2fe3d8.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n",
      "mixer_b16_224\n",
      "71.524\n",
      "Accuracy: 71.52%\n",
      "mixer_b16_224_in21k\n",
      "0.0\n",
      "Accuracy: 0.00%\n",
      "mixer_l16_224\n",
      "67.042\n",
      "Accuracy: 67.04%\n",
      "mixer_l16_224_in21k\n",
      "0.0\n",
      "Accuracy: 0.00%\n",
      "mixnet_l\n",
      "78.686\n",
      "Accuracy: 78.69%\n",
      "mixnet_m\n",
      "76.892\n",
      "Accuracy: 76.89%\n",
      "mixnet_s\n",
      "75.752\n",
      "Accuracy: 75.75%\n",
      "mixnet_xl\n",
      "80.262\n",
      "Accuracy: 80.26%\n",
      "mnasnet_100\n",
      "73.99\n",
      "Accuracy: 73.99%\n",
      "mobilenetv2_100\n",
      "72.636\n",
      "Accuracy: 72.64%\n",
      "mobilenetv2_110d\n",
      "74.824\n",
      "Accuracy: 74.82%\n",
      "mobilenetv2_120d\n",
      "77.26\n",
      "Accuracy: 77.26%\n",
      "mobilenetv2_140\n",
      "76.198\n",
      "Accuracy: 76.20%\n",
      "mobilenetv3_large_100\n",
      "75.288\n",
      "Accuracy: 75.29%\n",
      "mobilenetv3_large_100_miil\n",
      "0.54\n",
      "Accuracy: 0.54%\n",
      "mobilenetv3_large_100_miil_in21k\n",
      "0.004\n",
      "Accuracy: 0.00%\n",
      "mobilenetv3_rw\n",
      "74.95\n",
      "Accuracy: 74.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/nasnetalarge-a1897284.pth\" to C:\\Users\\user01/.cache\\torch\\hub\\checkpoints\\nasnetalarge-a1897284.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n",
      "nf_regnet_b1\n",
      "77.178\n",
      "Accuracy: 77.18%\n",
      "nf_resnet50\n",
      "78.844\n",
      "Accuracy: 78.84%\n",
      "nfnet_l0\n",
      "81.802\n",
      "Accuracy: 81.80%\n",
      "pit_b_224\n",
      "82.316\n",
      "Accuracy: 82.32%\n",
      "pit_b_distilled_224\n",
      "84.004\n",
      "Accuracy: 84.00%\n",
      "pit_s_224\n",
      "80.74\n",
      "Accuracy: 80.74%\n",
      "pit_s_distilled_224\n",
      "81.724\n",
      "Accuracy: 81.72%\n",
      "pit_ti_224\n",
      "72.266\n",
      "Accuracy: 72.27%\n",
      "pit_ti_distilled_224\n",
      "73.972\n",
      "Accuracy: 73.97%\n",
      "pit_xs_224\n",
      "77.844\n",
      "Accuracy: 77.84%\n",
      "pit_xs_distilled_224\n",
      "78.978\n",
      "Accuracy: 78.98%\n",
      "pnasnet5large\n",
      "58.894\n",
      "Accuracy: 58.89%\n",
      "regnetx_002\n",
      "67.608\n",
      "Accuracy: 67.61%\n",
      "regnetx_004\n",
      "71.378\n",
      "Accuracy: 71.38%\n",
      "regnetx_006\n",
      "73.0\n",
      "Accuracy: 73.00%\n",
      "regnetx_008\n",
      "74.272\n",
      "Accuracy: 74.27%\n",
      "regnetx_016\n",
      "76.552\n",
      "Accuracy: 76.55%\n",
      "regnetx_032\n",
      "77.656\n",
      "Accuracy: 77.66%\n",
      "regnetx_040\n",
      "78.172\n",
      "Accuracy: 78.17%\n",
      "regnetx_064\n",
      "78.78\n",
      "Accuracy: 78.78%\n",
      "regnetx_080\n",
      "78.718\n",
      "Accuracy: 78.72%\n",
      "regnetx_120\n",
      "79.18\n",
      "Accuracy: 79.18%\n",
      "regnetx_160\n",
      "79.654\n",
      "Accuracy: 79.65%\n",
      "regnetx_320\n",
      "79.962\n",
      "Accuracy: 79.96%\n",
      "regnety_002\n",
      "69.144\n",
      "Accuracy: 69.14%\n",
      "regnety_004\n",
      "72.936\n",
      "Accuracy: 72.94%\n",
      "regnety_006\n",
      "74.544\n",
      "Accuracy: 74.54%\n",
      "regnety_008\n",
      "75.824\n",
      "Accuracy: 75.82%\n",
      "regnety_016\n",
      "77.236\n",
      "Accuracy: 77.24%\n",
      "regnety_032\n",
      "81.776\n",
      "Accuracy: 81.78%\n",
      "regnety_040\n",
      "78.952\n",
      "Accuracy: 78.95%\n",
      "regnety_064\n",
      "79.458\n",
      "Accuracy: 79.46%\n",
      "regnety_080\n",
      "79.666\n",
      "Accuracy: 79.67%\n",
      "regnety_120\n",
      "80.236\n",
      "Accuracy: 80.24%\n",
      "regnety_160\n",
      "82.794\n",
      "Accuracy: 82.79%\n",
      "regnety_320\n",
      "80.656\n",
      "Accuracy: 80.66%\n",
      "repvgg_a2\n",
      "76.29\n",
      "Accuracy: 76.29%\n",
      "repvgg_b0\n",
      "74.946\n",
      "Accuracy: 74.95%\n",
      "repvgg_b1\n",
      "78.12\n",
      "Accuracy: 78.12%\n",
      "repvgg_b1g4\n",
      "77.578\n",
      "Accuracy: 77.58%\n",
      "repvgg_b2\n",
      "78.788\n",
      "Accuracy: 78.79%\n",
      "repvgg_b2g4\n",
      "79.492\n",
      "Accuracy: 79.49%\n",
      "repvgg_b3\n",
      "80.448\n",
      "Accuracy: 80.45%\n",
      "repvgg_b3g4\n",
      "80.07\n",
      "Accuracy: 80.07%\n",
      "res2net50_14w_8s\n",
      "77.824\n",
      "Accuracy: 77.82%\n",
      "res2net50_26w_4s\n",
      "77.864\n",
      "Accuracy: 77.86%\n",
      "res2net50_26w_6s\n",
      "78.362\n",
      "Accuracy: 78.36%\n",
      "res2net50_26w_8s\n",
      "78.84\n",
      "Accuracy: 78.84%\n",
      "res2net50_48w_2s\n",
      "77.286\n",
      "Accuracy: 77.29%\n",
      "res2net101_26w_4s\n",
      "79.008\n",
      "Accuracy: 79.01%\n",
      "res2next50\n",
      "77.98\n",
      "Accuracy: 77.98%\n",
      "resnest14d\n",
      "75.018\n",
      "Accuracy: 75.02%\n",
      "resnest26d\n",
      "78.31\n",
      "Accuracy: 78.31%\n",
      "resnest50d\n",
      "80.744\n",
      "Accuracy: 80.74%\n",
      "resnest50d_1s4x24d\n",
      "80.67\n",
      "Accuracy: 80.67%\n",
      "resnest50d_4s2x40d\n",
      "80.87\n",
      "Accuracy: 80.87%\n",
      "resnest101e\n",
      "81.942\n",
      "Accuracy: 81.94%\n",
      "resnest200e\n",
      "82.262\n",
      "Accuracy: 82.26%\n",
      "resnest269e\n",
      "78.662\n",
      "Accuracy: 78.66%\n",
      "resnet18\n",
      "69.224\n",
      "Accuracy: 69.22%\n",
      "resnet18d\n",
      "72.086\n",
      "Accuracy: 72.09%\n",
      "resnet26\n",
      "74.98\n",
      "Accuracy: 74.98%\n",
      "resnet26d\n",
      "76.354\n",
      "Accuracy: 76.35%\n",
      "resnet34\n",
      "74.512\n",
      "Accuracy: 74.51%\n",
      "resnet34d\n",
      "76.978\n",
      "Accuracy: 76.98%\n",
      "resnet50\n",
      "78.714\n",
      "Accuracy: 78.71%\n",
      "resnet50d\n",
      "80.294\n",
      "Accuracy: 80.29%\n",
      "resnet101d\n",
      "81.38\n",
      "Accuracy: 81.38%\n",
      "resnet152d\n",
      "82.05\n",
      "Accuracy: 82.05%\n",
      "resnet200d\n",
      "82.492\n",
      "Accuracy: 82.49%\n",
      "resnetblur50\n",
      "79.086\n",
      "Accuracy: 79.09%\n",
      "resnetrs50\n",
      "79.43\n",
      "Accuracy: 79.43%\n",
      "resnetrs101\n",
      "80.974\n",
      "Accuracy: 80.97%\n",
      "resnetrs152\n",
      "80.986\n",
      "Accuracy: 80.99%\n",
      "resnetrs200\n",
      "81.418\n",
      "Accuracy: 81.42%\n",
      "resnetrs270\n",
      "81.812\n",
      "Accuracy: 81.81%\n",
      "resnetrs350\n",
      "81.75\n",
      "Accuracy: 81.75%\n",
      "resnetrs420\n",
      "80.324\n",
      "Accuracy: 80.32%\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "HTTP Error 403: Forbidden\n",
      "resnext50_32x4d\n",
      "79.584\n",
      "Accuracy: 79.58%\n",
      "resnext50d_32x4d\n",
      "79.582\n",
      "Accuracy: 79.58%\n",
      "resnext101_32x8d\n",
      "79.068\n",
      "Accuracy: 79.07%\n",
      "rexnet_100\n",
      "77.788\n",
      "Accuracy: 77.79%\n",
      "rexnet_130\n",
      "79.286\n",
      "Accuracy: 79.29%\n",
      "rexnet_150\n",
      "80.184\n",
      "Accuracy: 80.18%\n",
      "rexnet_200\n",
      "81.482\n",
      "Accuracy: 81.48%\n",
      "selecsls42b\n",
      "76.944\n",
      "Accuracy: 76.94%\n",
      "selecsls60\n",
      "77.612\n",
      "Accuracy: 77.61%\n",
      "selecsls60b\n",
      "78.276\n",
      "Accuracy: 78.28%\n",
      "semnasnet_100\n",
      "74.87\n",
      "Accuracy: 74.87%\n",
      "seresnet50\n",
      "80.224\n",
      "Accuracy: 80.22%\n",
      "seresnet152d\n",
      "82.862\n",
      "Accuracy: 82.86%\n",
      "seresnext26d_32x4d\n",
      "77.584\n",
      "Accuracy: 77.58%\n",
      "seresnext26t_32x4d\n",
      "77.588\n",
      "Accuracy: 77.59%\n",
      "seresnext50_32x4d\n",
      "81.22\n",
      "Accuracy: 81.22%\n",
      "skresnet18\n",
      "72.586\n",
      "Accuracy: 72.59%\n",
      "skresnet34\n",
      "76.452\n",
      "Accuracy: 76.45%\n",
      "skresnext50_32x4d\n",
      "79.988\n",
      "Accuracy: 79.99%\n",
      "spnasnet_100\n",
      "73.906\n",
      "Accuracy: 73.91%\n",
      "ssl_resnet18\n",
      "72.412\n",
      "Accuracy: 72.41%\n",
      "ssl_resnet50\n",
      "79.182\n",
      "Accuracy: 79.18%\n",
      "ssl_resnext50_32x4d\n",
      "80.346\n",
      "Accuracy: 80.35%\n",
      "ssl_resnext101_32x4d\n",
      "81.008\n",
      "Accuracy: 81.01%\n",
      "ssl_resnext101_32x8d\n",
      "81.644\n",
      "Accuracy: 81.64%\n",
      "ssl_resnext101_32x16d\n",
      "81.86\n",
      "Accuracy: 81.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3191.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swin_base_patch4_window7_224\n",
      "84.81\n",
      "Accuracy: 84.81%\n",
      "swin_base_patch4_window7_224_in22k\n",
      "0.0\n",
      "Accuracy: 0.00%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "swin_large_patch4_window7_224\n",
      "86.018\n",
      "Accuracy: 86.02%\n",
      "swin_large_patch4_window7_224_in22k\n",
      "0.0\n",
      "Accuracy: 0.00%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "swin_small_patch4_window7_224\n",
      "82.944\n",
      "Accuracy: 82.94%\n",
      "swin_tiny_patch4_window7_224\n",
      "80.902\n",
      "Accuracy: 80.90%\n",
      "swsl_resnet18\n",
      "73.044\n",
      "Accuracy: 73.04%\n",
      "swsl_resnet50\n",
      "81.238\n",
      "Accuracy: 81.24%\n",
      "swsl_resnext50_32x4d\n",
      "82.142\n",
      "Accuracy: 82.14%\n",
      "swsl_resnext101_32x4d\n",
      "83.274\n",
      "Accuracy: 83.27%\n",
      "swsl_resnext101_32x8d\n",
      "84.528\n",
      "Accuracy: 84.53%\n",
      "swsl_resnext101_32x16d\n",
      "83.488\n",
      "Accuracy: 83.49%\n",
      "tf_efficientnet_b0\n",
      "75.794\n",
      "Accuracy: 75.79%\n",
      "tf_efficientnet_b0_ap\n",
      "15.386\n",
      "Accuracy: 15.39%\n",
      "tf_efficientnet_b0_ns\n",
      "77.736\n",
      "Accuracy: 77.74%\n",
      "tf_efficientnet_b1\n",
      "77.3\n",
      "Accuracy: 77.30%\n",
      "tf_efficientnet_b1_ap\n",
      "20.228\n",
      "Accuracy: 20.23%\n",
      "tf_efficientnet_b1_ns\n",
      "79.842\n",
      "Accuracy: 79.84%\n",
      "tf_efficientnet_b2\n",
      "77.224\n",
      "Accuracy: 77.22%\n",
      "tf_efficientnet_b2_ap\n",
      "6.652\n",
      "Accuracy: 6.65%\n",
      "tf_efficientnet_b2_ns\n",
      "79.506\n",
      "Accuracy: 79.51%\n",
      "tf_efficientnet_b3\n",
      "77.162\n",
      "Accuracy: 77.16%\n",
      "tf_efficientnet_b3_ap\n",
      "19.438\n",
      "Accuracy: 19.44%\n",
      "tf_efficientnet_b3_ns\n",
      "79.994\n",
      "Accuracy: 79.99%\n",
      "tf_efficientnet_b4\n",
      "76.708\n",
      "Accuracy: 76.71%\n",
      "tf_efficientnet_b4_ap\n",
      "24.908\n",
      "Accuracy: 24.91%\n",
      "tf_efficientnet_b4_ns\n",
      "79.368\n",
      "Accuracy: 79.37%\n",
      "tf_efficientnet_b5\n",
      "70.802\n",
      "Accuracy: 70.80%\n",
      "tf_efficientnet_b5_ap\n",
      "36.876\n",
      "Accuracy: 36.88%\n",
      "tf_efficientnet_b5_ns\n",
      "77.022\n",
      "Accuracy: 77.02%\n",
      "tf_efficientnet_b6\n",
      "75.346\n",
      "Accuracy: 75.35%\n",
      "tf_efficientnet_b6_ap\n",
      "67.734\n",
      "Accuracy: 67.73%\n",
      "tf_efficientnet_b6_ns\n",
      "72.13\n",
      "Accuracy: 72.13%\n",
      "tf_efficientnet_b7\n",
      "60.992\n",
      "Accuracy: 60.99%\n",
      "tf_efficientnet_b7_ap\n",
      "61.674\n",
      "Accuracy: 61.67%\n",
      "tf_efficientnet_b7_ns\n",
      "71.988\n",
      "Accuracy: 71.99%\n",
      "tf_efficientnet_b8\n",
      "61.17\n",
      "Accuracy: 61.17%\n",
      "tf_efficientnet_b8_ap\n",
      "23.77\n",
      "Accuracy: 23.77%\n",
      "tf_efficientnet_cc_b0_4e\n",
      "36.974\n",
      "Accuracy: 36.97%\n",
      "tf_efficientnet_cc_b0_8e\n",
      "45.528\n",
      "Accuracy: 45.53%\n",
      "tf_efficientnet_cc_b1_8e\n",
      "62.956\n",
      "Accuracy: 62.96%\n",
      "tf_efficientnet_el\n",
      "26.25\n",
      "Accuracy: 26.25%\n",
      "tf_efficientnet_em\n",
      "31.9\n",
      "Accuracy: 31.90%\n",
      "tf_efficientnet_es\n",
      "22.29\n",
      "Accuracy: 22.29%\n",
      "tf_efficientnet_l2_ns\n",
      "69.908\n",
      "Accuracy: 69.91%\n",
      "tf_efficientnet_l2_ns_475\n",
      "80.684\n",
      "Accuracy: 80.68%\n",
      "tf_efficientnet_lite0\n",
      "66.348\n",
      "Accuracy: 66.35%\n",
      "tf_efficientnet_lite1\n",
      "69.594\n",
      "Accuracy: 69.59%\n",
      "tf_efficientnet_lite2\n",
      "68.942\n",
      "Accuracy: 68.94%\n",
      "tf_efficientnet_lite3\n",
      "70.68\n",
      "Accuracy: 70.68%\n",
      "tf_efficientnet_lite4\n",
      "70.94\n",
      "Accuracy: 70.94%\n",
      "tf_efficientnetv2_b0\n",
      "77.34\n",
      "Accuracy: 77.34%\n",
      "tf_efficientnetv2_b1\n",
      "78.604\n",
      "Accuracy: 78.60%\n",
      "tf_efficientnetv2_b2\n",
      "78.834\n",
      "Accuracy: 78.83%\n",
      "tf_efficientnetv2_b3\n",
      "78.89\n",
      "Accuracy: 78.89%\n",
      "tf_efficientnetv2_l\n",
      "73.962\n",
      "Accuracy: 73.96%\n",
      "tf_efficientnetv2_l_in21ft1k\n",
      "8.294\n",
      "Accuracy: 8.29%\n",
      "tf_efficientnetv2_l_in21k\n",
      "0.002\n",
      "Accuracy: 0.00%\n",
      "tf_efficientnetv2_m\n",
      "71.014\n",
      "Accuracy: 71.01%\n",
      "tf_efficientnetv2_m_in21ft1k\n",
      "17.122\n",
      "Accuracy: 17.12%\n",
      "tf_efficientnetv2_m_in21k\n",
      "0.002\n",
      "Accuracy: 0.00%\n",
      "tf_efficientnetv2_s\n",
      "23.064\n",
      "Accuracy: 23.06%\n",
      "tf_efficientnetv2_s_in21ft1k\n",
      "13.176\n",
      "Accuracy: 13.18%\n",
      "tf_efficientnetv2_s_in21k\n",
      "0.002\n",
      "Accuracy: 0.00%\n",
      "tf_inception_v3\n",
      "42.912\n",
      "Accuracy: 42.91%\n",
      "tf_mixnet_l\n",
      "78.004\n",
      "Accuracy: 78.00%\n",
      "tf_mixnet_m\n",
      "76.19\n",
      "Accuracy: 76.19%\n",
      "tf_mixnet_s\n",
      "74.9\n",
      "Accuracy: 74.90%\n",
      "tf_mobilenetv3_large_075\n",
      "22.832\n",
      "Accuracy: 22.83%\n",
      "tf_mobilenetv3_large_100\n",
      "44.834\n",
      "Accuracy: 44.83%\n",
      "tf_mobilenetv3_large_minimal_100\n",
      "48.86\n",
      "Accuracy: 48.86%\n",
      "tf_mobilenetv3_small_075\n",
      "36.858\n",
      "Accuracy: 36.86%\n",
      "tf_mobilenetv3_small_100\n",
      "38.608\n",
      "Accuracy: 38.61%\n",
      "tf_mobilenetv3_small_minimal_100\n",
      "33.438\n",
      "Accuracy: 33.44%\n",
      "tnt_s_patch16_224\n",
      "76.982\n",
      "Accuracy: 76.98%\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "Please install InplaceABN:'pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12'\n",
      "tv_densenet121\n",
      "73.972\n",
      "Accuracy: 73.97%\n",
      "tv_resnet34\n",
      "72.814\n",
      "Accuracy: 72.81%\n",
      "tv_resnet50\n",
      "75.702\n",
      "Accuracy: 75.70%\n",
      "tv_resnet101\n",
      "76.972\n",
      "Accuracy: 76.97%\n",
      "tv_resnet152\n",
      "78.14\n",
      "Accuracy: 78.14%\n",
      "tv_resnext50_32x4d\n",
      "77.358\n",
      "Accuracy: 77.36%\n",
      "vgg11\n",
      "68.764\n",
      "Accuracy: 68.76%\n",
      "vgg11_bn\n",
      "70.062\n",
      "Accuracy: 70.06%\n",
      "vgg13\n",
      "69.646\n",
      "Accuracy: 69.65%\n",
      "vgg13_bn\n",
      "71.448\n",
      "Accuracy: 71.45%\n",
      "vgg16\n",
      "71.492\n",
      "Accuracy: 71.49%\n",
      "vgg16_bn\n",
      "73.356\n",
      "Accuracy: 73.36%\n",
      "vgg19\n",
      "72.19\n",
      "Accuracy: 72.19%\n",
      "vgg19_bn\n",
      "73.906\n",
      "Accuracy: 73.91%\n",
      "vit_base_patch16_224\n",
      "75.188\n",
      "Accuracy: 75.19%\n",
      "vit_base_patch16_224_in21k\n",
      "0.1\n",
      "Accuracy: 0.10%\n",
      "vit_base_patch16_224_miil\n",
      "33.744\n",
      "Accuracy: 33.74%\n",
      "vit_base_patch16_224_miil_in21k\n",
      "0.012\n",
      "Accuracy: 0.01%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_base_patch32_224_in21k\n",
      "0.1\n",
      "Accuracy: 0.10%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_base_r50_s16_224_in21k\n",
      "0.1\n",
      "Accuracy: 0.10%\n",
      "The size of tensor a (197) must match the size of tensor b (577) at non-singleton dimension 1\n",
      "vit_deit_base_distilled_patch16_224\n",
      "83.12\n",
      "Accuracy: 83.12%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_deit_base_patch16_224\n",
      "81.896\n",
      "Accuracy: 81.90%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_deit_small_distilled_patch16_224\n",
      "80.892\n",
      "Accuracy: 80.89%\n",
      "vit_deit_small_patch16_224\n",
      "79.432\n",
      "Accuracy: 79.43%\n",
      "vit_deit_tiny_distilled_patch16_224\n",
      "74.252\n",
      "Accuracy: 74.25%\n",
      "vit_deit_tiny_patch16_224\n",
      "71.52\n",
      "Accuracy: 71.52%\n",
      "unexpected EOF, expected 1745388 more bytes. The file might be corrupted.\n",
      "vit_large_patch16_224_in21k\n",
      "0.002\n",
      "Accuracy: 0.00%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_large_patch32_224_in21k\n",
      "0.1\n",
      "Accuracy: 0.10%\n",
      "Input image size (224*224) doesn't match model (384*384).\n",
      "vit_small_patch16_224\n",
      "77.338\n",
      "Accuracy: 77.34%\n",
      "wide_resnet50_2\n",
      "81.506\n",
      "Accuracy: 81.51%\n",
      "wide_resnet101_2\n",
      "78.82\n",
      "Accuracy: 78.82%\n",
      "xception\n",
      "67.422\n",
      "Accuracy: 67.42%\n",
      "xception41\n",
      "7.552\n",
      "Accuracy: 7.55%\n",
      "xception65\n",
      "21.228\n",
      "Accuracy: 21.23%\n",
      "xception71\n",
      "4.448\n",
      "Accuracy: 4.45%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import pandas as pd\n",
    "\n",
    "# Define data directory path and batch size\n",
    "data_dir = 'C:/Users/user01/Documents/val'\n",
    "# data_dir = '/content/drive/MyDrive/soleymani/oo-dis/'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "image_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "data_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "models=[]\n",
    "acces=[]\n",
    "# Load pre-trained TIMM ResNet-50 model\n",
    "# model = timm.create_model('vit_large_patch16_224', pretrained=True)\n",
    "lists=timm.list_models(pretrained=True)\n",
    "for i in range(50,len(lists)):\n",
    "  try:\n",
    "\n",
    "    \n",
    "    model = timm.create_model(lists[i], pretrained=True)\n",
    "\n",
    "    model.cuda()\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define variables for accuracy calculation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    maps={}\n",
    "    # Iterate through dataset\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # # print(predicted)\n",
    "            # # print(labels)\n",
    "            # for j in range(len(predicted)):\n",
    "            #     predicted[j]=mapClss[predicted[j].item()]\n",
    "            #     # if labels[i].item() not in maps.keys():\n",
    "            #     #   maps[labels[i].item()]=[predicted[i].item()]\n",
    "            #     # else:\n",
    "            #     #   maps[labels[i].item()].append(predicted[i].item())\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    print(lists[i])\n",
    "    models.append(lists[i])\n",
    "    print(accuracy)\n",
    "    acces.append(accuracy)\n",
    "    df=pd.DataFrame()\n",
    "    df['model']=models\n",
    "    df['ood-dis']=acces\n",
    "    df.to_csv('in_supervised_50k.csv')\n",
    "    torch.cuda.empty_cache()\n",
    "    # Print accuracy\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5111\n",
      "adv_inception_v3\n",
      "54.94517308105784\n",
      "Accuracy: 54.95%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m# Iterate through dataset\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mfor\u001b[39;00m inputs, labels \u001b[39min\u001b[39;00m data_loader:\n\u001b[0;32m     46\u001b[0m         inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     47\u001b[0m         labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 381\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1027\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1030\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1034\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     94\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import pandas as pd\n",
    "\n",
    "# Define data directory path and batch size\n",
    "data_dir = 'E:/ood-dis/'\n",
    "# data_dir = '/content/drive/MyDrive/soleymani/oo-dis/'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "image_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "data_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "models=[]\n",
    "acces=[]\n",
    "# Load pre-trained TIMM ResNet-50 model\n",
    "# model = timm.create_model('vit_large_patch16_224', pretrained=True)\n",
    "lists=timm.list_models(pretrained=True)\n",
    "for i in range(0,len(lists)):\n",
    "    # print(lists[i])\n",
    "    # models.append(lists[i])\n",
    "    model = timm.create_model('resnet50', pretrained=True)\n",
    "\n",
    "    model.cuda()\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Define variables for accuracy calculation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    maps={}\n",
    "    # Iterate through dataset\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # print(predicted)\n",
    "            # print(labels)\n",
    "            # print('pred=>',predicted)\n",
    "            # print('labels=>',labels)\n",
    "            for j in range(len(predicted)):\n",
    "                predicted[j]=mapClss[predicted[j].item()]\n",
    "                # if labels[i].item() not in maps.keys():\n",
    "                #   maps[labels[i].item()]=[predicted[i].item()]\n",
    "                # else:\n",
    "                #   maps[labels[i].item()].append(predicted[i].item())\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    print(correct)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(lists[i])\n",
    "    models.append(lists[i])\n",
    "    print(accuracy)\n",
    "    acces.append(accuracy)\n",
    "    df=pd.DataFrame()\n",
    "    df['model']=models\n",
    "    df['ood-dis']=acces\n",
    "    df.to_csv('ood_supervised_1_icml.csv')\n",
    "    torch.cuda.empty_cache()\n",
    "    # Print accuracy\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4,\n",
       " 2: 6,\n",
       " 3: 9,\n",
       " 4: 11,\n",
       " 5: 13,\n",
       " 6: 22,\n",
       " 7: 23,\n",
       " 8: 26,\n",
       " 9: 29,\n",
       " 10: 31,\n",
       " 11: 39,\n",
       " 12: 47,\n",
       " 13: 63,\n",
       " 14: 71,\n",
       " 15: 76,\n",
       " 16: 79,\n",
       " 17: 84,\n",
       " 18: 90,\n",
       " 19: 94,\n",
       " 20: 96,\n",
       " 21: 97,\n",
       " 22: 99,\n",
       " 23: 100,\n",
       " 24: 105,\n",
       " 25: 107,\n",
       " 26: 113,\n",
       " 27: 122,\n",
       " 28: 125,\n",
       " 29: 129,\n",
       " 30: 130,\n",
       " 31: 132,\n",
       " 32: 144,\n",
       " 33: 147,\n",
       " 34: 148,\n",
       " 35: 151,\n",
       " 36: 155,\n",
       " 37: 160,\n",
       " 38: 161,\n",
       " 39: 162,\n",
       " 40: 163,\n",
       " 41: 171,\n",
       " 42: 172,\n",
       " 43: 178,\n",
       " 44: 187,\n",
       " 45: 195,\n",
       " 46: 199,\n",
       " 47: 203,\n",
       " 48: 207,\n",
       " 49: 208,\n",
       " 50: 219,\n",
       " 51: 231,\n",
       " 52: 232,\n",
       " 53: 234,\n",
       " 54: 235,\n",
       " 55: 242,\n",
       " 56: 245,\n",
       " 57: 247,\n",
       " 58: 250,\n",
       " 59: 251,\n",
       " 60: 254,\n",
       " 61: 259,\n",
       " 62: 260,\n",
       " 63: 263,\n",
       " 64: 264,\n",
       " 65: 265,\n",
       " 66: 267,\n",
       " 67: 269,\n",
       " 68: 276,\n",
       " 69: 281,\n",
       " 70: 288,\n",
       " 71: 289,\n",
       " 72: 291,\n",
       " 73: 292,\n",
       " 74: 293,\n",
       " 75: 299,\n",
       " 76: 301,\n",
       " 77: 308,\n",
       " 78: 309,\n",
       " 79: 311,\n",
       " 80: 312,\n",
       " 81: 314,\n",
       " 82: 315,\n",
       " 83: 319,\n",
       " 84: 323,\n",
       " 85: 327,\n",
       " 86: 334,\n",
       " 87: 335,\n",
       " 88: 337,\n",
       " 89: 338,\n",
       " 90: 340,\n",
       " 91: 341,\n",
       " 92: 344,\n",
       " 93: 347,\n",
       " 94: 353,\n",
       " 95: 355,\n",
       " 96: 361,\n",
       " 97: 362,\n",
       " 98: 365,\n",
       " 99: 367,\n",
       " 100: 368,\n",
       " 101: 372,\n",
       " 102: 388,\n",
       " 103: 393,\n",
       " 104: 397,\n",
       " 105: 401,\n",
       " 106: 407,\n",
       " 107: 412,\n",
       " 108: 414,\n",
       " 109: 417,\n",
       " 110: 418,\n",
       " 111: 421,\n",
       " 112: 422,\n",
       " 113: 424,\n",
       " 114: 425,\n",
       " 115: 426,\n",
       " 116: 427,\n",
       " 117: 428,\n",
       " 118: 430,\n",
       " 119: 433,\n",
       " 120: 434,\n",
       " 121: 435,\n",
       " 122: 437,\n",
       " 123: 440,\n",
       " 124: 441,\n",
       " 125: 446,\n",
       " 126: 447,\n",
       " 127: 448,\n",
       " 128: 453,\n",
       " 129: 457,\n",
       " 130: 462,\n",
       " 131: 463,\n",
       " 132: 465,\n",
       " 133: 469,\n",
       " 134: 470,\n",
       " 135: 471,\n",
       " 136: 472,\n",
       " 137: 476,\n",
       " 138: 478,\n",
       " 139: 483,\n",
       " 140: 487,\n",
       " 141: 488,\n",
       " 142: 499,\n",
       " 143: 512,\n",
       " 144: 515,\n",
       " 145: 546,\n",
       " 146: 555,\n",
       " 147: 558,\n",
       " 148: 561,\n",
       " 149: 570,\n",
       " 150: 572,\n",
       " 151: 579,\n",
       " 152: 583,\n",
       " 153: 587,\n",
       " 154: 593,\n",
       " 155: 594,\n",
       " 156: 596,\n",
       " 157: 604,\n",
       " 158: 605,\n",
       " 159: 609,\n",
       " 160: 610,\n",
       " 161: 613,\n",
       " 162: 617,\n",
       " 163: 618,\n",
       " 164: 619,\n",
       " 165: 621,\n",
       " 166: 623,\n",
       " 167: 625,\n",
       " 168: 626,\n",
       " 169: 629,\n",
       " 170: 635,\n",
       " 171: 637,\n",
       " 172: 644,\n",
       " 173: 653,\n",
       " 174: 656,\n",
       " 175: 657,\n",
       " 176: 658,\n",
       " 177: 681,\n",
       " 178: 684,\n",
       " 179: 693,\n",
       " 180: 696,\n",
       " 181: 701,\n",
       " 182: 709,\n",
       " 183: 717,\n",
       " 184: 723,\n",
       " 185: 724,\n",
       " 186: 730,\n",
       " 187: 753,\n",
       " 188: 754,\n",
       " 189: 763,\n",
       " 190: 768,\n",
       " 191: 774,\n",
       " 192: 776,\n",
       " 193: 777,\n",
       " 194: 779,\n",
       " 195: 780,\n",
       " 196: 787,\n",
       " 197: 805,\n",
       " 198: 806,\n",
       " 199: 812,\n",
       " 200: 815,\n",
       " 201: 820,\n",
       " 202: 824,\n",
       " 203: 827,\n",
       " 204: 833,\n",
       " 205: 835,\n",
       " 206: 836,\n",
       " 207: 847,\n",
       " 208: 852,\n",
       " 209: 866,\n",
       " 210: 875,\n",
       " 211: 883,\n",
       " 212: 889,\n",
       " 213: 895,\n",
       " 214: 907,\n",
       " 215: 928,\n",
       " 216: 931,\n",
       " 217: 932,\n",
       " 218: 933,\n",
       " 219: 934,\n",
       " 220: 937,\n",
       " 221: 943,\n",
       " 222: 947,\n",
       " 223: 948,\n",
       " 224: 949,\n",
       " 225: 951,\n",
       " 226: 953,\n",
       " 227: 954,\n",
       " 228: 957,\n",
       " 229: 963,\n",
       " 230: 965,\n",
       " 231: 967,\n",
       " 232: 980,\n",
       " 233: 981,\n",
       " 234: 983,\n",
       " 235: 988,\n",
       " 236: 236,\n",
       " 237: 237,\n",
       " 238: 238,\n",
       " 239: 239,\n",
       " 240: 240,\n",
       " 241: 241,\n",
       " 242: 242,\n",
       " 243: 243,\n",
       " 244: 244,\n",
       " 245: 245,\n",
       " 246: 246,\n",
       " 247: 247,\n",
       " 248: 248,\n",
       " 249: 249,\n",
       " 250: 250,\n",
       " 251: 251,\n",
       " 252: 252,\n",
       " 253: 253,\n",
       " 254: 254,\n",
       " 255: 255,\n",
       " 256: 256,\n",
       " 257: 257,\n",
       " 258: 258,\n",
       " 259: 259,\n",
       " 260: 260,\n",
       " 261: 261,\n",
       " 262: 262,\n",
       " 263: 263,\n",
       " 264: 264,\n",
       " 265: 265,\n",
       " 266: 266,\n",
       " 267: 267,\n",
       " 268: 268,\n",
       " 269: 269,\n",
       " 270: 270,\n",
       " 271: 271,\n",
       " 272: 272,\n",
       " 273: 273,\n",
       " 274: 274,\n",
       " 275: 275,\n",
       " 276: 276,\n",
       " 277: 277,\n",
       " 278: 278,\n",
       " 279: 279,\n",
       " 280: 280,\n",
       " 281: 281,\n",
       " 282: 282,\n",
       " 283: 283,\n",
       " 284: 284,\n",
       " 285: 285,\n",
       " 286: 286,\n",
       " 287: 287,\n",
       " 288: 288,\n",
       " 289: 289,\n",
       " 290: 290,\n",
       " 291: 291,\n",
       " 292: 292,\n",
       " 293: 293,\n",
       " 294: 294,\n",
       " 295: 295,\n",
       " 296: 296,\n",
       " 297: 297,\n",
       " 298: 298,\n",
       " 299: 299,\n",
       " 300: 300,\n",
       " 301: 301,\n",
       " 302: 302,\n",
       " 303: 303,\n",
       " 304: 304,\n",
       " 305: 305,\n",
       " 306: 306,\n",
       " 307: 307,\n",
       " 308: 308,\n",
       " 309: 309,\n",
       " 310: 310,\n",
       " 311: 311,\n",
       " 312: 312,\n",
       " 313: 313,\n",
       " 314: 314,\n",
       " 315: 315,\n",
       " 316: 316,\n",
       " 317: 317,\n",
       " 318: 318,\n",
       " 319: 319,\n",
       " 320: 320,\n",
       " 321: 321,\n",
       " 322: 322,\n",
       " 323: 323,\n",
       " 324: 324,\n",
       " 325: 325,\n",
       " 326: 326,\n",
       " 327: 327,\n",
       " 328: 328,\n",
       " 329: 329,\n",
       " 330: 330,\n",
       " 331: 331,\n",
       " 332: 332,\n",
       " 333: 333,\n",
       " 334: 334,\n",
       " 335: 335,\n",
       " 336: 336,\n",
       " 337: 337,\n",
       " 338: 338,\n",
       " 339: 339,\n",
       " 340: 340,\n",
       " 341: 341,\n",
       " 342: 342,\n",
       " 343: 343,\n",
       " 344: 344,\n",
       " 345: 345,\n",
       " 346: 346,\n",
       " 347: 347,\n",
       " 348: 348,\n",
       " 349: 349,\n",
       " 350: 350,\n",
       " 351: 351,\n",
       " 352: 352,\n",
       " 353: 353,\n",
       " 354: 354,\n",
       " 355: 355,\n",
       " 356: 356,\n",
       " 357: 357,\n",
       " 358: 358,\n",
       " 359: 359,\n",
       " 360: 360,\n",
       " 361: 361,\n",
       " 362: 362,\n",
       " 363: 363,\n",
       " 364: 364,\n",
       " 365: 365,\n",
       " 366: 366,\n",
       " 367: 367,\n",
       " 368: 368,\n",
       " 369: 369,\n",
       " 370: 370,\n",
       " 371: 371,\n",
       " 372: 372,\n",
       " 373: 373,\n",
       " 374: 374,\n",
       " 375: 375,\n",
       " 376: 376,\n",
       " 377: 377,\n",
       " 378: 378,\n",
       " 379: 379,\n",
       " 380: 380,\n",
       " 381: 381,\n",
       " 382: 382,\n",
       " 383: 383,\n",
       " 384: 384,\n",
       " 385: 385,\n",
       " 386: 386,\n",
       " 387: 387,\n",
       " 388: 388,\n",
       " 389: 389,\n",
       " 390: 390,\n",
       " 391: 391,\n",
       " 392: 392,\n",
       " 393: 393,\n",
       " 394: 394,\n",
       " 395: 395,\n",
       " 396: 396,\n",
       " 397: 397,\n",
       " 398: 398,\n",
       " 399: 399,\n",
       " 400: 400,\n",
       " 401: 401,\n",
       " 402: 402,\n",
       " 403: 403,\n",
       " 404: 404,\n",
       " 405: 405,\n",
       " 406: 406,\n",
       " 407: 407,\n",
       " 408: 408,\n",
       " 409: 409,\n",
       " 410: 410,\n",
       " 411: 411,\n",
       " 412: 412,\n",
       " 413: 413,\n",
       " 414: 414,\n",
       " 415: 415,\n",
       " 416: 416,\n",
       " 417: 417,\n",
       " 418: 418,\n",
       " 419: 419,\n",
       " 420: 420,\n",
       " 421: 421,\n",
       " 422: 422,\n",
       " 423: 423,\n",
       " 424: 424,\n",
       " 425: 425,\n",
       " 426: 426,\n",
       " 427: 427,\n",
       " 428: 428,\n",
       " 429: 429,\n",
       " 430: 430,\n",
       " 431: 431,\n",
       " 432: 432,\n",
       " 433: 433,\n",
       " 434: 434,\n",
       " 435: 435,\n",
       " 436: 436,\n",
       " 437: 437,\n",
       " 438: 438,\n",
       " 439: 439,\n",
       " 440: 440,\n",
       " 441: 441,\n",
       " 442: 442,\n",
       " 443: 443,\n",
       " 444: 444,\n",
       " 445: 445,\n",
       " 446: 446,\n",
       " 447: 447,\n",
       " 448: 448,\n",
       " 449: 449,\n",
       " 450: 450,\n",
       " 451: 451,\n",
       " 452: 452,\n",
       " 453: 453,\n",
       " 454: 454,\n",
       " 455: 455,\n",
       " 456: 456,\n",
       " 457: 457,\n",
       " 458: 458,\n",
       " 459: 459,\n",
       " 460: 460,\n",
       " 461: 461,\n",
       " 462: 462,\n",
       " 463: 463,\n",
       " 464: 464,\n",
       " 465: 465,\n",
       " 466: 466,\n",
       " 467: 467,\n",
       " 468: 468,\n",
       " 469: 469,\n",
       " 470: 470,\n",
       " 471: 471,\n",
       " 472: 472,\n",
       " 473: 473,\n",
       " 474: 474,\n",
       " 475: 475,\n",
       " 476: 476,\n",
       " 477: 477,\n",
       " 478: 478,\n",
       " 479: 479,\n",
       " 480: 480,\n",
       " 481: 481,\n",
       " 482: 482,\n",
       " 483: 483,\n",
       " 484: 484,\n",
       " 485: 485,\n",
       " 486: 486,\n",
       " 487: 487,\n",
       " 488: 488,\n",
       " 489: 489,\n",
       " 490: 490,\n",
       " 491: 491,\n",
       " 492: 492,\n",
       " 493: 493,\n",
       " 494: 494,\n",
       " 495: 495,\n",
       " 496: 496,\n",
       " 497: 497,\n",
       " 498: 498,\n",
       " 499: 499,\n",
       " 500: 500,\n",
       " 501: 501,\n",
       " 502: 502,\n",
       " 503: 503,\n",
       " 504: 504,\n",
       " 505: 505,\n",
       " 506: 506,\n",
       " 507: 507,\n",
       " 508: 508,\n",
       " 509: 509,\n",
       " 510: 510,\n",
       " 511: 511,\n",
       " 512: 512,\n",
       " 513: 513,\n",
       " 514: 514,\n",
       " 515: 515,\n",
       " 516: 516,\n",
       " 517: 517,\n",
       " 518: 518,\n",
       " 519: 519,\n",
       " 520: 520,\n",
       " 521: 521,\n",
       " 522: 522,\n",
       " 523: 523,\n",
       " 524: 524,\n",
       " 525: 525,\n",
       " 526: 526,\n",
       " 527: 527,\n",
       " 528: 528,\n",
       " 529: 529,\n",
       " 530: 530,\n",
       " 531: 531,\n",
       " 532: 532,\n",
       " 533: 533,\n",
       " 534: 534,\n",
       " 535: 535,\n",
       " 536: 536,\n",
       " 537: 537,\n",
       " 538: 538,\n",
       " 539: 539,\n",
       " 540: 540,\n",
       " 541: 541,\n",
       " 542: 542,\n",
       " 543: 543,\n",
       " 544: 544,\n",
       " 545: 545,\n",
       " 546: 546,\n",
       " 547: 547,\n",
       " 548: 548,\n",
       " 549: 549,\n",
       " 550: 550,\n",
       " 551: 551,\n",
       " 552: 552,\n",
       " 553: 553,\n",
       " 554: 554,\n",
       " 555: 555,\n",
       " 556: 556,\n",
       " 557: 557,\n",
       " 558: 558,\n",
       " 559: 559,\n",
       " 560: 560,\n",
       " 561: 561,\n",
       " 562: 562,\n",
       " 563: 563,\n",
       " 564: 564,\n",
       " 565: 565,\n",
       " 566: 566,\n",
       " 567: 567,\n",
       " 568: 568,\n",
       " 569: 569,\n",
       " 570: 570,\n",
       " 571: 571,\n",
       " 572: 572,\n",
       " 573: 573,\n",
       " 574: 574,\n",
       " 575: 575,\n",
       " 576: 576,\n",
       " 577: 577,\n",
       " 578: 578,\n",
       " 579: 579,\n",
       " 580: 580,\n",
       " 581: 581,\n",
       " 582: 582,\n",
       " 583: 583,\n",
       " 584: 584,\n",
       " 585: 585,\n",
       " 586: 586,\n",
       " 587: 587,\n",
       " 588: 588,\n",
       " 589: 589,\n",
       " 590: 590,\n",
       " 591: 591,\n",
       " 592: 592,\n",
       " 593: 593,\n",
       " 594: 594,\n",
       " 595: 595,\n",
       " 596: 596,\n",
       " 597: 597,\n",
       " 598: 598,\n",
       " 599: 599,\n",
       " 600: 600,\n",
       " 601: 601,\n",
       " 602: 602,\n",
       " 603: 603,\n",
       " 604: 604,\n",
       " 605: 605,\n",
       " 606: 606,\n",
       " 607: 607,\n",
       " 608: 608,\n",
       " 609: 609,\n",
       " 610: 610,\n",
       " 611: 611,\n",
       " 612: 612,\n",
       " 613: 613,\n",
       " 614: 614,\n",
       " 615: 615,\n",
       " 616: 616,\n",
       " 617: 617,\n",
       " 618: 618,\n",
       " 619: 619,\n",
       " 620: 620,\n",
       " 621: 621,\n",
       " 622: 622,\n",
       " 623: 623,\n",
       " 624: 624,\n",
       " 625: 625,\n",
       " 626: 626,\n",
       " 627: 627,\n",
       " 628: 628,\n",
       " 629: 629,\n",
       " 630: 630,\n",
       " 631: 631,\n",
       " 632: 632,\n",
       " 633: 633,\n",
       " 634: 634,\n",
       " 635: 635,\n",
       " 636: 636,\n",
       " 637: 637,\n",
       " 638: 638,\n",
       " 639: 639,\n",
       " 640: 640,\n",
       " 641: 641,\n",
       " 642: 642,\n",
       " 643: 643,\n",
       " 644: 644,\n",
       " 645: 645,\n",
       " 646: 646,\n",
       " 647: 647,\n",
       " 648: 648,\n",
       " 649: 649,\n",
       " 650: 650,\n",
       " 651: 651,\n",
       " 652: 652,\n",
       " 653: 653,\n",
       " 654: 654,\n",
       " 655: 655,\n",
       " 656: 656,\n",
       " 657: 657,\n",
       " 658: 658,\n",
       " 659: 659,\n",
       " 660: 660,\n",
       " 661: 661,\n",
       " 662: 662,\n",
       " 663: 663,\n",
       " 664: 664,\n",
       " 665: 665,\n",
       " 666: 666,\n",
       " 667: 667,\n",
       " 668: 668,\n",
       " 669: 669,\n",
       " 670: 670,\n",
       " 671: 671,\n",
       " 672: 672,\n",
       " 673: 673,\n",
       " 674: 674,\n",
       " 675: 675,\n",
       " 676: 676,\n",
       " 677: 677,\n",
       " 678: 678,\n",
       " 679: 679,\n",
       " 680: 680,\n",
       " 681: 681,\n",
       " 682: 682,\n",
       " 683: 683,\n",
       " 684: 684,\n",
       " 685: 685,\n",
       " 686: 686,\n",
       " 687: 687,\n",
       " 688: 688,\n",
       " 689: 689,\n",
       " 690: 690,\n",
       " 691: 691,\n",
       " 692: 692,\n",
       " 693: 693,\n",
       " 694: 694,\n",
       " 695: 695,\n",
       " 696: 696,\n",
       " 697: 697,\n",
       " 698: 698,\n",
       " 699: 699,\n",
       " 700: 700,\n",
       " 701: 701,\n",
       " 702: 702,\n",
       " 703: 703,\n",
       " 704: 704,\n",
       " 705: 705,\n",
       " 706: 706,\n",
       " 707: 707,\n",
       " 708: 708,\n",
       " 709: 709,\n",
       " 710: 710,\n",
       " 711: 711,\n",
       " 712: 712,\n",
       " 713: 713,\n",
       " 714: 714,\n",
       " 715: 715,\n",
       " 716: 716,\n",
       " 717: 717,\n",
       " 718: 718,\n",
       " 719: 719,\n",
       " 720: 720,\n",
       " 721: 721,\n",
       " 722: 722,\n",
       " 723: 723,\n",
       " 724: 724,\n",
       " 725: 725,\n",
       " 726: 726,\n",
       " 727: 727,\n",
       " 728: 728,\n",
       " 729: 729,\n",
       " 730: 730,\n",
       " 731: 731,\n",
       " 732: 732,\n",
       " 733: 733,\n",
       " 734: 734,\n",
       " 735: 735,\n",
       " 736: 736,\n",
       " 737: 737,\n",
       " 738: 738,\n",
       " 739: 739,\n",
       " 740: 740,\n",
       " 741: 741,\n",
       " 742: 742,\n",
       " 743: 743,\n",
       " 744: 744,\n",
       " 745: 745,\n",
       " 746: 746,\n",
       " 747: 747,\n",
       " 748: 748,\n",
       " 749: 749,\n",
       " 750: 750,\n",
       " 751: 751,\n",
       " 752: 752,\n",
       " 753: 753,\n",
       " 754: 754,\n",
       " 755: 755,\n",
       " 756: 756,\n",
       " 757: 757,\n",
       " 758: 758,\n",
       " 759: 759,\n",
       " 760: 760,\n",
       " 761: 761,\n",
       " 762: 762,\n",
       " 763: 763,\n",
       " 764: 764,\n",
       " 765: 765,\n",
       " 766: 766,\n",
       " 767: 767,\n",
       " 768: 768,\n",
       " 769: 769,\n",
       " 770: 770,\n",
       " 771: 771,\n",
       " 772: 772,\n",
       " 773: 773,\n",
       " 774: 774,\n",
       " 775: 775,\n",
       " 776: 776,\n",
       " 777: 777,\n",
       " 778: 778,\n",
       " 779: 779,\n",
       " 780: 780,\n",
       " 781: 781,\n",
       " 782: 782,\n",
       " 783: 783,\n",
       " 784: 784,\n",
       " 785: 785,\n",
       " 786: 786,\n",
       " 787: 787,\n",
       " 788: 788,\n",
       " 789: 789,\n",
       " 790: 790,\n",
       " 791: 791,\n",
       " 792: 792,\n",
       " 793: 793,\n",
       " 794: 794,\n",
       " 795: 795,\n",
       " 796: 796,\n",
       " 797: 797,\n",
       " 798: 798,\n",
       " 799: 799,\n",
       " 800: 800,\n",
       " 801: 801,\n",
       " 802: 802,\n",
       " 803: 803,\n",
       " 804: 804,\n",
       " 805: 805,\n",
       " 806: 806,\n",
       " 807: 807,\n",
       " 808: 808,\n",
       " 809: 809,\n",
       " 810: 810,\n",
       " 811: 811,\n",
       " 812: 812,\n",
       " 813: 813,\n",
       " 814: 814,\n",
       " 815: 815,\n",
       " 816: 816,\n",
       " 817: 817,\n",
       " 818: 818,\n",
       " 819: 819,\n",
       " 820: 820,\n",
       " 821: 821,\n",
       " 822: 822,\n",
       " 823: 823,\n",
       " 824: 824,\n",
       " 825: 825,\n",
       " 826: 826,\n",
       " 827: 827,\n",
       " 828: 828,\n",
       " 829: 829,\n",
       " 830: 830,\n",
       " 831: 831,\n",
       " 832: 832,\n",
       " 833: 833,\n",
       " 834: 834,\n",
       " 835: 835,\n",
       " 836: 836,\n",
       " 837: 837,\n",
       " 838: 838,\n",
       " 839: 839,\n",
       " 840: 840,\n",
       " 841: 841,\n",
       " 842: 842,\n",
       " 843: 843,\n",
       " 844: 844,\n",
       " 845: 845,\n",
       " 846: 846,\n",
       " 847: 847,\n",
       " 848: 848,\n",
       " 849: 849,\n",
       " 850: 850,\n",
       " 851: 851,\n",
       " 852: 852,\n",
       " 853: 853,\n",
       " 854: 854,\n",
       " 855: 855,\n",
       " 856: 856,\n",
       " 857: 857,\n",
       " 858: 858,\n",
       " 859: 859,\n",
       " 860: 860,\n",
       " 861: 861,\n",
       " 862: 862,\n",
       " 863: 863,\n",
       " 864: 864,\n",
       " 865: 865,\n",
       " 866: 866,\n",
       " 867: 867,\n",
       " 868: 868,\n",
       " 869: 869,\n",
       " 870: 870,\n",
       " 871: 871,\n",
       " 872: 872,\n",
       " 873: 873,\n",
       " 874: 874,\n",
       " 875: 875,\n",
       " 876: 876,\n",
       " 877: 877,\n",
       " 878: 878,\n",
       " 879: 879,\n",
       " 880: 880,\n",
       " 881: 881,\n",
       " 882: 882,\n",
       " 883: 883,\n",
       " 884: 884,\n",
       " 885: 885,\n",
       " 886: 886,\n",
       " 887: 887,\n",
       " 888: 888,\n",
       " 889: 889,\n",
       " 890: 890,\n",
       " 891: 891,\n",
       " 892: 892,\n",
       " 893: 893,\n",
       " 894: 894,\n",
       " 895: 895,\n",
       " 896: 896,\n",
       " 897: 897,\n",
       " 898: 898,\n",
       " 899: 899,\n",
       " 900: 900,\n",
       " 901: 901,\n",
       " 902: 902,\n",
       " 903: 903,\n",
       " 904: 904,\n",
       " 905: 905,\n",
       " 906: 906,\n",
       " 907: 907,\n",
       " 908: 908,\n",
       " 909: 909,\n",
       " 910: 910,\n",
       " 911: 911,\n",
       " 912: 912,\n",
       " 913: 913,\n",
       " 914: 914,\n",
       " 915: 915,\n",
       " 916: 916,\n",
       " 917: 917,\n",
       " 918: 918,\n",
       " 919: 919,\n",
       " 920: 920,\n",
       " 921: 921,\n",
       " 922: 922,\n",
       " 923: 923,\n",
       " 924: 924,\n",
       " 925: 925,\n",
       " 926: 926,\n",
       " 927: 927,\n",
       " 928: 928,\n",
       " 929: 929,\n",
       " 930: 930,\n",
       " 931: 931,\n",
       " 932: 932,\n",
       " 933: 933,\n",
       " 934: 934,\n",
       " 935: 935,\n",
       " 936: 936,\n",
       " 937: 937,\n",
       " 938: 938,\n",
       " 939: 939,\n",
       " 940: 940,\n",
       " 941: 941,\n",
       " 942: 942,\n",
       " 943: 943,\n",
       " 944: 944,\n",
       " 945: 945,\n",
       " 946: 946,\n",
       " 947: 947,\n",
       " 948: 948,\n",
       " 949: 949,\n",
       " 950: 950,\n",
       " 951: 951,\n",
       " 952: 952,\n",
       " 953: 953,\n",
       " 954: 954,\n",
       " 955: 955,\n",
       " 956: 956,\n",
       " 957: 957,\n",
       " 958: 958,\n",
       " 959: 959,\n",
       " 960: 960,\n",
       " 961: 961,\n",
       " 962: 962,\n",
       " 963: 963,\n",
       " 964: 964,\n",
       " 965: 965,\n",
       " 966: 966,\n",
       " 967: 967,\n",
       " 968: 968,\n",
       " 969: 969,\n",
       " 970: 970,\n",
       " 971: 971,\n",
       " 972: 972,\n",
       " 973: 973,\n",
       " 974: 974,\n",
       " 975: 975,\n",
       " 976: 976,\n",
       " 977: 977,\n",
       " 978: 978,\n",
       " 979: 979,\n",
       " 980: 980,\n",
       " 981: 981,\n",
       " 982: 982,\n",
       " 983: 983,\n",
       " 984: 984,\n",
       " 985: 985,\n",
       " 986: 986,\n",
       " 987: 987,\n",
       " 988: 988,\n",
       " 989: 989,\n",
       " 990: 990,\n",
       " 991: 991,\n",
       " 992: 992,\n",
       " 993: 993,\n",
       " 994: 994,\n",
       " 995: 995,\n",
       " 996: 996,\n",
       " 997: 997,\n",
       " 998: 998,\n",
       " 999: 999,\n",
       " 1000: 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapClss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import timm\n",
    "import pandas as pd\n",
    "\n",
    "# Define data directory path and batch size\n",
    "data_dir = 'E:/in-dis'\n",
    "# data_dir = '/content/drive/MyDrive/soleymani/oo-dis/'\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "image_dataset = datasets.ImageFolder(data_dir, transform=data_transforms)\n",
    "data_loader = torch.utils.data.DataLoader(image_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n01443537': 0,\n",
       " 'n01494475': 1,\n",
       " 'n01498041': 2,\n",
       " 'n01518878': 3,\n",
       " 'n01531178': 4,\n",
       " 'n01534433': 5,\n",
       " 'n01614925': 6,\n",
       " 'n01616318': 7,\n",
       " 'n01630670': 8,\n",
       " 'n01632777': 9,\n",
       " 'n01644373': 10,\n",
       " 'n01677366': 11,\n",
       " 'n01694178': 12,\n",
       " 'n01748264': 13,\n",
       " 'n01770393': 14,\n",
       " 'n01774750': 15,\n",
       " 'n01784675': 16,\n",
       " 'n01806143': 17,\n",
       " 'n01820546': 18,\n",
       " 'n01833805': 19,\n",
       " 'n01843383': 20,\n",
       " 'n01847000': 21,\n",
       " 'n01855672': 22,\n",
       " 'n01860187': 23,\n",
       " 'n01882714': 24,\n",
       " 'n01910747': 25,\n",
       " 'n01944390': 26,\n",
       " 'n01983481': 27,\n",
       " 'n01986214': 28,\n",
       " 'n02006656': 29,\n",
       " 'n02007558': 30,\n",
       " 'n02009912': 31,\n",
       " 'n02051845': 32,\n",
       " 'n02066245': 33,\n",
       " 'n02071294': 34,\n",
       " 'n02085620': 35,\n",
       " 'n02086240': 36,\n",
       " 'n02088094': 37,\n",
       " 'n02088238': 38,\n",
       " 'n02088364': 39,\n",
       " 'n02088466': 40,\n",
       " 'n02091032': 41,\n",
       " 'n02091134': 42,\n",
       " 'n02092339': 43,\n",
       " 'n02094433': 44,\n",
       " 'n02096585': 45,\n",
       " 'n02097298': 46,\n",
       " 'n02098286': 47,\n",
       " 'n02099601': 48,\n",
       " 'n02099712': 49,\n",
       " 'n02102318': 50,\n",
       " 'n02106030': 51,\n",
       " 'n02106166': 52,\n",
       " 'n02106550': 53,\n",
       " 'n02106662': 54,\n",
       " 'n02108089': 55,\n",
       " 'n02108915': 56,\n",
       " 'n02109525': 57,\n",
       " 'n02110185': 58,\n",
       " 'n02110341': 59,\n",
       " 'n02110958': 60,\n",
       " 'n02112018': 61,\n",
       " 'n02112137': 62,\n",
       " 'n02113023': 63,\n",
       " 'n02113186': 64,\n",
       " 'n02113624': 65,\n",
       " 'n02113799': 66,\n",
       " 'n02114367': 67,\n",
       " 'n02117135': 68,\n",
       " 'n02123045': 69,\n",
       " 'n02128385': 70,\n",
       " 'n02128757': 71,\n",
       " 'n02129165': 72,\n",
       " 'n02129604': 73,\n",
       " 'n02130308': 74,\n",
       " 'n02138441': 75,\n",
       " 'n02165456': 76,\n",
       " 'n02190166': 77,\n",
       " 'n02206856': 78,\n",
       " 'n02226429': 79,\n",
       " 'n02229544': 80,\n",
       " 'n02233338': 81,\n",
       " 'n02236044': 82,\n",
       " 'n02268443': 83,\n",
       " 'n02279972': 84,\n",
       " 'n02317335': 85,\n",
       " 'n02346627': 86,\n",
       " 'n02356798': 87,\n",
       " 'n02363005': 88,\n",
       " 'n02364673': 89,\n",
       " 'n02391049': 90,\n",
       " 'n02395406': 91,\n",
       " 'n02398521': 92,\n",
       " 'n02410509': 93,\n",
       " 'n02423022': 94,\n",
       " 'n02437616': 95,\n",
       " 'n02445715': 96,\n",
       " 'n02447366': 97,\n",
       " 'n02480495': 98,\n",
       " 'n02481823': 99,\n",
       " 'n02483362': 100,\n",
       " 'n02486410': 101,\n",
       " 'n02510455': 102,\n",
       " 'n02607072': 103,\n",
       " 'n02655020': 104,\n",
       " 'n02672831': 105,\n",
       " 'n02701002': 106,\n",
       " 'n02747177': 107,\n",
       " 'n02769748': 108,\n",
       " 'n02782093': 109,\n",
       " 'n02783161': 110,\n",
       " 'n02788148': 111,\n",
       " 'n02790996': 112,\n",
       " 'n02791270': 113,\n",
       " 'n02793495': 114,\n",
       " 'n02794156': 115,\n",
       " 'n02795169': 116,\n",
       " 'n02797295': 117,\n",
       " 'n02802426': 118,\n",
       " 'n02807133': 119,\n",
       " 'n02808304': 120,\n",
       " 'n02808440': 121,\n",
       " 'n02814860': 122,\n",
       " 'n02823428': 123,\n",
       " 'n02823750': 124,\n",
       " 'n02840245': 125,\n",
       " 'n02841315': 126,\n",
       " 'n02843684': 127,\n",
       " 'n02870880': 128,\n",
       " 'n02883205': 129,\n",
       " 'n02906734': 130,\n",
       " 'n02909870': 131,\n",
       " 'n02916936': 132,\n",
       " 'n02939185': 133,\n",
       " 'n02948072': 134,\n",
       " 'n02950826': 135,\n",
       " 'n02951358': 136,\n",
       " 'n02966193': 137,\n",
       " 'n02971356': 138,\n",
       " 'n02980441': 139,\n",
       " 'n02992529': 140,\n",
       " 'n02999410': 141,\n",
       " 'n03041632': 142,\n",
       " 'n03109150': 143,\n",
       " 'n03124170': 144,\n",
       " 'n03272010': 145,\n",
       " 'n03345487': 146,\n",
       " 'n03372029': 147,\n",
       " 'n03384352': 148,\n",
       " 'n03424325': 149,\n",
       " 'n03443371': 150,\n",
       " 'n03452741': 151,\n",
       " 'n03467068': 152,\n",
       " 'n03481172': 153,\n",
       " 'n03494278': 154,\n",
       " 'n03495258': 155,\n",
       " 'n03498962': 156,\n",
       " 'n03544143': 157,\n",
       " 'n03584254': 158,\n",
       " 'n03594945': 159,\n",
       " 'n03595614': 160,\n",
       " 'n03602883': 161,\n",
       " 'n03630383': 162,\n",
       " 'n03633091': 163,\n",
       " 'n03637318': 164,\n",
       " 'n03649909': 165,\n",
       " 'n03658185': 166,\n",
       " 'n03662601': 167,\n",
       " 'n03666591': 168,\n",
       " 'n03676483': 169,\n",
       " 'n03706229': 170,\n",
       " 'n03710193': 171,\n",
       " 'n03729826': 172,\n",
       " 'n03764736': 173,\n",
       " 'n03770679': 174,\n",
       " 'n03773504': 175,\n",
       " 'n03775071': 176,\n",
       " 'n03832673': 177,\n",
       " 'n03840681': 178,\n",
       " 'n03873416': 179,\n",
       " 'n03876231': 180,\n",
       " 'n03888257': 181,\n",
       " 'n03908618': 182,\n",
       " 'n03930630': 183,\n",
       " 'n03944341': 184,\n",
       " 'n03947888': 185,\n",
       " 'n03967562': 186,\n",
       " 'n04040759': 187,\n",
       " 'n04041544': 188,\n",
       " 'n04086273': 189,\n",
       " 'n04118538': 190,\n",
       " 'n04133789': 191,\n",
       " 'n04141076': 192,\n",
       " 'n04141327': 193,\n",
       " 'n04146614': 194,\n",
       " 'n04147183': 195,\n",
       " 'n04192698': 196,\n",
       " 'n04254680': 197,\n",
       " 'n04254777': 198,\n",
       " 'n04266014': 199,\n",
       " 'n04275548': 200,\n",
       " 'n04310018': 201,\n",
       " 'n04325704': 202,\n",
       " 'n04330267': 203,\n",
       " 'n04347754': 204,\n",
       " 'n04355338': 205,\n",
       " 'n04355933': 206,\n",
       " 'n04389033': 207,\n",
       " 'n04409515': 208,\n",
       " 'n04465501': 209,\n",
       " 'n04487394': 210,\n",
       " 'n04522168': 211,\n",
       " 'n04536866': 212,\n",
       " 'n04552348': 213,\n",
       " 'n04591713': 214,\n",
       " 'n07614500': 215,\n",
       " 'n07693725': 216,\n",
       " 'n07695742': 217,\n",
       " 'n07697313': 218,\n",
       " 'n07697537': 219,\n",
       " 'n07714990': 220,\n",
       " 'n07718472': 221,\n",
       " 'n07734744': 222,\n",
       " 'n07742313': 223,\n",
       " 'n07745940': 224,\n",
       " 'n07749582': 225,\n",
       " 'n07753275': 226,\n",
       " 'n07753592': 227,\n",
       " 'n07768694': 228,\n",
       " 'n07873807': 229,\n",
       " 'n07880968': 230,\n",
       " 'n07920052': 231,\n",
       " 'n09472597': 232,\n",
       " 'n09835506': 233,\n",
       " 'n10565667': 234,\n",
       " 'n12267677': 235}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapClss={}\n",
    "for a in range(1,1001):\n",
    "    mapClss[a]=a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BRACS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
