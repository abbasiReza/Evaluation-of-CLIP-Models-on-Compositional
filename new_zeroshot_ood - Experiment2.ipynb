{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accordion',\n",
       " 'acorn',\n",
       " 'afghan hound',\n",
       " 'african chameleon',\n",
       " 'ambulance',\n",
       " 'american egret',\n",
       " 'american lobster',\n",
       " 'anemone fish',\n",
       " 'axolotl',\n",
       " 'baboon',\n",
       " 'backpack',\n",
       " 'badger',\n",
       " 'bagel',\n",
       " 'bald eagle',\n",
       " 'balloon',\n",
       " 'ballplayer',\n",
       " 'ballpoint',\n",
       " 'banana',\n",
       " 'bannister',\n",
       " 'barbell',\n",
       " 'barbershop',\n",
       " 'barn',\n",
       " 'barometer',\n",
       " 'barrel',\n",
       " 'barrow',\n",
       " 'basketball',\n",
       " 'basset',\n",
       " 'bath towel',\n",
       " 'bathtub',\n",
       " 'beacon',\n",
       " 'beagle',\n",
       " 'beaver',\n",
       " 'bee',\n",
       " 'beer bottle',\n",
       " 'beer glass',\n",
       " 'binder',\n",
       " 'binoculars',\n",
       " 'birdhouse',\n",
       " 'bison',\n",
       " 'black swan',\n",
       " 'bloodhound',\n",
       " 'bookcase',\n",
       " 'border collie',\n",
       " 'boston bull',\n",
       " 'bow tie',\n",
       " 'boxer',\n",
       " 'broccoli',\n",
       " 'broom',\n",
       " 'bucket',\n",
       " 'bulletproof vest',\n",
       " 'burrito',\n",
       " 'caldron',\n",
       " 'candle',\n",
       " 'cannon',\n",
       " 'canoe',\n",
       " 'cardigan',\n",
       " 'carousel',\n",
       " 'carton',\n",
       " 'castle',\n",
       " 'cellular telephone',\n",
       " 'centipede',\n",
       " 'chain',\n",
       " 'cheeseburger',\n",
       " 'cheetah',\n",
       " 'chihuahua',\n",
       " 'chimpanzee',\n",
       " 'chow',\n",
       " 'cleaver',\n",
       " 'cocker spaniel',\n",
       " 'cockroach',\n",
       " 'collie',\n",
       " 'common iguana',\n",
       " 'common newt',\n",
       " 'corkscrew',\n",
       " 'cowboy hat',\n",
       " 'cricket',\n",
       " 'cucumber',\n",
       " 'dalmatian',\n",
       " 'dragonfly',\n",
       " 'drake',\n",
       " 'electric guitar',\n",
       " 'espresso',\n",
       " 'fire engine',\n",
       " 'flamingo',\n",
       " 'flute',\n",
       " 'fly',\n",
       " 'forklift',\n",
       " 'fox squirrel',\n",
       " 'french bulldog',\n",
       " 'gasmask',\n",
       " 'gazelle',\n",
       " 'german shepherd',\n",
       " 'giant panda',\n",
       " 'gibbon',\n",
       " 'goblet',\n",
       " 'golden retriever',\n",
       " 'goldfinch',\n",
       " 'goldfish',\n",
       " 'goose',\n",
       " 'grand piano',\n",
       " 'granny smith',\n",
       " 'grasshopper',\n",
       " 'grey whale',\n",
       " 'guillotine',\n",
       " 'guinea pig',\n",
       " 'hammer',\n",
       " 'hammerhead',\n",
       " 'harmonica',\n",
       " 'harp',\n",
       " 'hatchet',\n",
       " 'hermit crab',\n",
       " 'hippopotamus',\n",
       " 'hog',\n",
       " 'hotdog',\n",
       " 'hourglass',\n",
       " 'hummingbird',\n",
       " 'hyena',\n",
       " 'ice cream',\n",
       " 'indian cobra',\n",
       " 'ipod',\n",
       " 'italian greyhound',\n",
       " 'jeep',\n",
       " 'jellyfish',\n",
       " 'jersey',\n",
       " 'joystick',\n",
       " 'junco',\n",
       " 'killer whale',\n",
       " 'koala',\n",
       " 'lab coat',\n",
       " 'labrador retriever',\n",
       " 'ladle',\n",
       " 'ladybug',\n",
       " 'lampshade',\n",
       " 'lawn mower',\n",
       " 'lemon',\n",
       " 'leopard',\n",
       " 'letter opener',\n",
       " 'lifeboat',\n",
       " 'lighter',\n",
       " 'lion',\n",
       " 'lipstick',\n",
       " 'llama',\n",
       " 'lorikeet',\n",
       " 'magnetic compass',\n",
       " 'mailbox',\n",
       " 'mantis',\n",
       " 'matchstick',\n",
       " 'meerkat',\n",
       " 'milk can',\n",
       " 'minivan',\n",
       " 'missile',\n",
       " 'mitten',\n",
       " 'monarch',\n",
       " 'mushroom',\n",
       " 'notebook',\n",
       " 'ocarina',\n",
       " 'orangutan',\n",
       " 'ostrich',\n",
       " 'paddle',\n",
       " 'paintbrush',\n",
       " 'parachute',\n",
       " 'peacock',\n",
       " 'pelican',\n",
       " 'pembroke',\n",
       " 'pencil box',\n",
       " 'pickup',\n",
       " 'pineapple',\n",
       " 'pinwheel',\n",
       " 'pirate',\n",
       " 'pizza',\n",
       " 'plow',\n",
       " 'pomegranate',\n",
       " 'pomeranian',\n",
       " 'porcupine',\n",
       " 'pretzel',\n",
       " 'puffer',\n",
       " 'pug',\n",
       " 'radiator',\n",
       " 'radio',\n",
       " 'revolver',\n",
       " 'rottweiler',\n",
       " 'rugby ball',\n",
       " 'saint bernard',\n",
       " 'sandal',\n",
       " 'sax',\n",
       " 'scabbard',\n",
       " 'school bus',\n",
       " 'schooner',\n",
       " 'scorpion',\n",
       " 'scotch terrier',\n",
       " 'scuba diver',\n",
       " 'shield',\n",
       " 'shih-tzu',\n",
       " 'siberian husky',\n",
       " 'skunk',\n",
       " 'snail',\n",
       " 'snow leopard',\n",
       " 'soccer ball',\n",
       " 'sock',\n",
       " 'space shuttle',\n",
       " 'spider web',\n",
       " 'spoonbill',\n",
       " 'standard poodle',\n",
       " 'starfish',\n",
       " 'steam locomotive',\n",
       " 'stingray',\n",
       " 'stole',\n",
       " 'stove',\n",
       " 'strawberry',\n",
       " 'submarine',\n",
       " 'sundial',\n",
       " 'sunglass',\n",
       " 'swimming cap',\n",
       " 'tabby',\n",
       " 'tank',\n",
       " 'tarantula',\n",
       " 'tennis ball',\n",
       " 'tiger',\n",
       " 'timber wolf',\n",
       " 'toucan',\n",
       " 'toy poodle',\n",
       " 'tractor',\n",
       " 'tree frog',\n",
       " 'trombone',\n",
       " 'vase',\n",
       " 'violin',\n",
       " 'volcano',\n",
       " 'vulture',\n",
       " 'warplane',\n",
       " 'weimaraner',\n",
       " 'west highland white terrier',\n",
       " 'whippet',\n",
       " 'wine bottle',\n",
       " 'yorkshire terrier',\n",
       " 'zebra']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import open_clip\n",
    "texts = os.listdir('E:/only_objs')\n",
    "texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_IMAGENET_TEMPLATES = (\n",
    "    lambda c: f'a bad photo of a {c}.',\n",
    "    lambda c: f'a photo of many {c}.',\n",
    "    lambda c: f'a sculpture of a {c}.',\n",
    "    lambda c: f'a photo of the hard to see {c}.',\n",
    "    lambda c: f'a low resolution photo of the {c}.',\n",
    "    lambda c: f'a rendering of a {c}.',\n",
    "    lambda c: f'graffiti of a {c}.',\n",
    "    lambda c: f'a bad photo of the {c}.',\n",
    "    lambda c: f'a cropped photo of the {c}.',\n",
    "    lambda c: f'a tattoo of a {c}.',\n",
    "    lambda c: f'the embroidered {c}.',\n",
    "    lambda c: f'a photo of a hard to see {c}.',\n",
    "    lambda c: f'a bright photo of a {c}.',\n",
    "    lambda c: f'a photo of a clean {c}.',\n",
    "    lambda c: f'a photo of a dirty {c}.',\n",
    "    lambda c: f'a dark photo of the {c}.',\n",
    "    lambda c: f'a drawing of a {c}.',\n",
    "    lambda c: f'a photo of my {c}.',\n",
    "    lambda c: f'the plastic {c}.',\n",
    "    lambda c: f'a photo of the cool {c}.',\n",
    "    lambda c: f'a close-up photo of a {c}.',\n",
    "    lambda c: f'a black and white photo of the {c}.',\n",
    "    lambda c: f'a painting of the {c}.',\n",
    "    lambda c: f'a painting of a {c}.',\n",
    "    lambda c: f'a pixelated photo of the {c}.',\n",
    "    lambda c: f'a sculpture of the {c}.',\n",
    "    lambda c: f'a bright photo of the {c}.',\n",
    "    lambda c: f'a cropped photo of a {c}.',\n",
    "    lambda c: f'a plastic {c}.',\n",
    "    lambda c: f'a photo of the dirty {c}.',\n",
    "    lambda c: f'a jpeg corrupted photo of a {c}.',\n",
    "    lambda c: f'a blurry photo of the {c}.',\n",
    "    lambda c: f'a photo of the {c}.',\n",
    "    lambda c: f'a good photo of the {c}.',\n",
    "    lambda c: f'a rendering of the {c}.',\n",
    "    lambda c: f'a {c} in a video game.',\n",
    "    lambda c: f'a photo of one {c}.',\n",
    "    lambda c: f'a doodle of a {c}.',\n",
    "    lambda c: f'a close-up photo of the {c}.',\n",
    "    lambda c: f'a photo of a {c}.',\n",
    "    lambda c: f'the origami {c}.',\n",
    "    lambda c: f'the {c} in a video game.',\n",
    "    lambda c: f'a sketch of a {c}.',\n",
    "    lambda c: f'a doodle of the {c}.',\n",
    "    lambda c: f'a origami {c}.',\n",
    "    lambda c: f'a low resolution photo of a {c}.',\n",
    "    lambda c: f'the toy {c}.',\n",
    "    lambda c: f'a rendition of the {c}.',\n",
    "    lambda c: f'a photo of the clean {c}.',\n",
    "    lambda c: f'a photo of a large {c}.',\n",
    "    lambda c: f'a rendition of a {c}.',\n",
    "    lambda c: f'a photo of a nice {c}.',\n",
    "    lambda c: f'a photo of a weird {c}.',\n",
    "    lambda c: f'a blurry photo of a {c}.',\n",
    "    lambda c: f'a cartoon {c}.',\n",
    "    lambda c: f'art of a {c}.',\n",
    "    lambda c: f'a sketch of the {c}.',\n",
    "    lambda c: f'a embroidered {c}.',\n",
    "    lambda c: f'a pixelated photo of a {c}.',\n",
    "    lambda c: f'itap of the {c}.',\n",
    "    lambda c: f'a jpeg corrupted photo of the {c}.',\n",
    "    lambda c: f'a good photo of a {c}.',\n",
    "    lambda c: f'a plushie {c}.',\n",
    "    lambda c: f'a photo of the nice {c}.',\n",
    "    lambda c: f'a photo of the small {c}.',\n",
    "    lambda c: f'a photo of the weird {c}.',\n",
    "    lambda c: f'the cartoon {c}.',\n",
    "    lambda c: f'art of the {c}.',\n",
    "    lambda c: f'a drawing of the {c}.',\n",
    "    lambda c: f'a photo of the large {c}.',\n",
    "    lambda c: f'a black and white photo of a {c}.',\n",
    "    lambda c: f'the plushie {c}.',\n",
    "    lambda c: f'a dark photo of a {c}.',\n",
    "    lambda c: f'itap of a {c}.',\n",
    "    lambda c: f'graffiti of the {c}.',\n",
    "    lambda c: f'a toy {c}.',\n",
    "    lambda c: f'itap of my {c}.',\n",
    "    lambda c: f'a photo of a cool {c}.',\n",
    "    lambda c: f'a photo of a small {c}.',\n",
    "    lambda c: f'a tattoo of the {c}.',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts=[]\n",
    "texts=sorted(texts)\n",
    "for text in texts:\n",
    "    for a in OPENAI_IMAGENET_TEMPLATES:\n",
    "        # print(a(text))\n",
    "        all_texts.append(a(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "all_models=open_clip.list_pretrained()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    # print(pred)\n",
    "    # print(target)\n",
    "\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    # print(correct)\n",
    "    # print([float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk])\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>in_dis_Acc_top1</th>\n",
       "      <th>in_dis_Acc_top5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, in_dis_Acc_top1, in_dis_Acc_top5]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_in=pd.DataFrame(columns=['model','in_dis_Acc_top1','in_dis_Acc_top5'])\n",
    "df_in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT-bigG-14', 'laion2b_s39b_b160k'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'coca_ViT-L-14', 'mscoco_finetuned_laion2b_s13b_b90k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'coca_ViT-L-14_mscoco_finetuned_laion2b_s13b_b90k', 'in_dis_Acc_top1': 0.3287803828780383, 'in_dis_Acc_top5': 0.4668745966874597}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autocast = torch.cuda.amp.autocast\n",
    "cast_dtype = None\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('coca_ViT-L-14', pretrained='commonpool_xl_s13b_b90k')\n",
    "tokenizer = open_clip.get_tokenizer('coca_ViT-L-14')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "dataset=torchvision.datasets.ImageFolder('E:/final_dataset/',transform=preprocess)\n",
    "dataloader=torch.utils.data.DataLoader(dataset,shuffle=False,batch_size=64\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "# Example list of texts to encode\n",
    "\n",
    "with torch.no_grad():\n",
    "# Specify batch size\n",
    "    batch_size = 80\n",
    "\n",
    "    # Encode texts in batches\n",
    "    text_features_target = []\n",
    "    for i in range(0, len(all_texts), batch_size):\n",
    "        batch_texts = all_texts[i:i+batch_size]\n",
    "        text = tokenizer(batch_texts)\n",
    "        with torch.no_grad():\n",
    "            text_features_batch = F.normalize(model.encode_text(text.cuda()))\n",
    "            # text.cuda()\n",
    "            # print(text_features_batch.shape)\n",
    "            text_features_batch=text_features_batch.mean(dim=0)\n",
    "\n",
    "            # text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "            text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # print(text_features_batch.unsqueeze(0).shape)\n",
    "            # print(text_features_batch.mean(dim=0).shape)\n",
    "            text_features_target.append(text_features_batch.unsqueeze(0))\n",
    "\n",
    "    # Concatenate text features from batches\n",
    "    text_features_target = torch.cat(text_features_target, dim=0)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    top1, top5, n = 0., 0., 0.\n",
    "    for images, target in dataloader:\n",
    "        images = images.to('cuda')\n",
    "        if cast_dtype is not None:\n",
    "            images = images.to(dtype=cast_dtype)\n",
    "        target = target.to('cuda')\n",
    "\n",
    "\n",
    "        with autocast():\n",
    "            # predict\n",
    "            image_features = model.encode_image(images)\n",
    "            # image_features = F.normalize(image_features, dim=-1)\n",
    "            logits = 100. * image_features @ text_features_target.T\n",
    "        # print(image_features.shape)\n",
    "        # measure accuracy\n",
    "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "        # print(acc1, acc5)\n",
    "        top1 += acc1\n",
    "        top5 += acc5\n",
    "        n += images.size(0)\n",
    "    \n",
    "top1 = (top1 / n)\n",
    "top5 = (top5 / n)\n",
    "# row={'model':a[0]+'_'+a[1],'in_dis_Acc_top1':top1,'in_dis_Acc_top5':top5}\n",
    "print(row)\n",
    "# df_in = df_in.append(row, ignore_index=True)\n",
    "# df_in.to_csv('all_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5734566573456658\n",
      "0.8778231877823188\n"
     ]
    }
   ],
   "source": [
    "print(top1)\n",
    "print(top5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autocast = torch.cuda.amp.autocast\n",
    "cast_dtype = None\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='commonpool_xl_s13b_b90k')\n",
    "tokenizer = open_clip.get_tokenizer('ViT-L-14')\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "dataset=torchvision.datasets.ImageFolder('E:/final_dataset/',transform=preprocess)\n",
    "dataloader=torch.utils.data.DataLoader(dataset,shuffle=True,batch_size=64\n",
    "                                )\n",
    "\n",
    "\n",
    "\n",
    "# Example list of texts to encode\n",
    "\n",
    "with torch.no_grad():\n",
    "# Specify batch size\n",
    "    batch_size = 80\n",
    "\n",
    "    # Encode texts in batches\n",
    "    text_features_target = []\n",
    "    for i in range(0, len(all_texts), batch_size):\n",
    "        batch_texts = all_texts[i:i+batch_size]\n",
    "        text = tokenizer(batch_texts)\n",
    "        with torch.no_grad():\n",
    "            text_features_batch = F.normalize(model.encode_text(text.cuda()))\n",
    "            # text.cuda()\n",
    "            # print(text_features_batch.shape)\n",
    "            text_features_batch=text_features_batch.mean(dim=0)\n",
    "\n",
    "            # text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "            text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # print(text_features_batch.unsqueeze(0).shape)\n",
    "            # print(text_features_batch.mean(dim=0).shape)\n",
    "            text_features_target.append(text_features_batch.unsqueeze(0))\n",
    "\n",
    "    # Concatenate text features from batches\n",
    "    text_features_target = torch.cat(text_features_target, dim=0)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    top1, top5, n = 0., 0., 0.\n",
    "    for images, target in dataloader:\n",
    "        images = images.to('cuda')\n",
    "        if cast_dtype is not None:\n",
    "            images = images.to(dtype=cast_dtype)\n",
    "        target = target.to('cuda')\n",
    "\n",
    "\n",
    "        with autocast():\n",
    "            # predict\n",
    "            image_features = model.encode_image(images)\n",
    "            # image_features = F.normalize(image_features, dim=-1)\n",
    "            logits = 100. * image_features @ text_features_target.T\n",
    "        # print(image_features.shape)\n",
    "        # measure accuracy\n",
    "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "        # print(acc1, acc5)\n",
    "        top1 += acc1\n",
    "        top5 += acc5\n",
    "        n += images.size(0)\n",
    "    \n",
    "top1 = (top1 / n)\n",
    "top5 = (top5 / n)\n",
    "# row={'model':a[0]+'_'+a[1],'in_dis_Acc_top1':top1,'in_dis_Acc_top5':top5}\n",
    "# print(row)\n",
    "# df_in = df_in.append(row, ignore_index=True)\n",
    "# df_in.to_csv('all_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0021510002151000217\n",
      "0.010217251021725103\n"
     ]
    }
   ],
   "source": [
    "print(top1)\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('coca_ViT-B-32', 'laion2b_s13b_b90k')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models[76]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'xlm-roberta-large-ViT-H-14_frozen_laion5b_s13b_b90k', 'in_dis_Acc_top1': 0.8519435770431787, 'in_dis_Acc_top5': 0.9477764617206849}\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "Please `pip install timm` to use timm models.\n",
      "{'model': 'coca_ViT-B-32_laion2b_s13b_b90k', 'in_dis_Acc_top1': 0.7626790136750297, 'in_dis_Acc_top5': 0.9095509852481964}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">47</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">44 │   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">45 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">46 │   │   │   </span>top1, top5, n = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>47 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> images, target <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> dataloader:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">48 │   │   │   │   </span>images = images.to(<span style=\"color: #808000; text-decoration-color: #808000\">'cuda'</span>)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> cast_dtype <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 │   │   │   │   │   </span>images = images.to(dtype=cast_dtype)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">628</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 625 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sampler_iter <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 626 │   │   │   │   # TODO(https://github.com/pytorch/pytorch/issues/76750)</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 627 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._reset()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[call-arg]</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 628 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_data()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 629 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._num_yielded += <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 630 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_kind == _DatasetKind.Iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 631 │   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._IterableDataset_len_called <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> \\                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">671</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 668 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 669 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_next_data</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 670 │   │   </span>index = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._next_index()  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 671 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._dataset_fetcher.fetch(index)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># may raise StopIteration</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 672 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 673 │   │   │   </span>data = _utils.pin_memory.pin_memory(data, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._pin_memory_device)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 674 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> data                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">58</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fetch</span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset, <span style=\"color: #808000; text-decoration-color: #808000\">\"__getitems__\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__:         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 │   │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__(possibly_batched_index)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>58 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">59 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">60 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">58</span> in   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset, <span style=\"color: #808000; text-decoration-color: #808000\">\"__getitems__\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__:         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">56 │   │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset.__getitems__(possibly_batched_index)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">57 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>58 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>data = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[idx] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> idx <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> possibly_batched_index]                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">59 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">60 │   │   │   </span>data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataset[possibly_batched_index]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">61 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.collate_fn(data)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">229</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">tuple: (sample, target) where target is class_index of the target class.</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">228 │   │   </span>path, target = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.samples[index]                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>229 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>sample = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.loader(path)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">230 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transform <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">231 │   │   │   </span>sample = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.transform(sample)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">232 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.target_transform <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">268</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">default_loader</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">265 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> get_image_backend() == <span style=\"color: #808000; text-decoration-color: #808000\">\"accimage\"</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">266 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> accimage_loader(path)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">267 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>268 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> pil_loader(path)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">269 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">270 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">271 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">ImageFolder</span>(DatasetFolder):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">248</span> in    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pil_loader</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">245 │   # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillo</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">246 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(path, <span style=\"color: #808000; text-decoration-color: #808000\">\"rb\"</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> f:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">247 │   │   </span>img = Image.open(f)                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>248 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> img.convert(<span style=\"color: #808000; text-decoration-color: #808000\">\"RGB\"</span>)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">249 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">250 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">251 # TODO: specify the return type</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\PIL\\Image.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">921</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 918 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">:returns: An :py:class:`~PIL.Image.Image` object.</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 919 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 920 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 921 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.load()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 922 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 923 │   │   </span>has_transparency = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.info.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"transparency\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 924 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> mode <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mode == <span style=\"color: #808000; text-decoration-color: #808000\">\"P\"</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\PIL\\ImageFile.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">260</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">257 │   │   │   │   │   │   │   │   │   </span>)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">258 │   │   │   │   │   │   │   </span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">259 │   │   │   │   │   │   │   </span>b = b + s                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>260 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>n, err_code = decoder.decode(b)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">261 │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> n &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">262 │   │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">263 │   │   │   │   │   │   │   </span>b = b[n:]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m47\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m45 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m\u001b[2m│   │   │   \u001b[0mtop1, top5, n = \u001b[94m0.\u001b[0m, \u001b[94m0.\u001b[0m, \u001b[94m0.\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m47 \u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m images, target \u001b[95min\u001b[0m dataloader:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mimages = images.to(\u001b[33m'\u001b[0m\u001b[33mcuda\u001b[0m\u001b[33m'\u001b[0m)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m cast_dtype \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mimages = images.to(dtype=cast_dtype)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:\u001b[94m628\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__next__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 625 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._sampler_iter \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 626 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 627 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._reset()  \u001b[2m# type: ignore[call-arg]\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 628 \u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m._next_data()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 629 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._num_yielded += \u001b[94m1\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 630 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._dataset_kind == _DatasetKind.Iterable \u001b[95mand\u001b[0m \\                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 631 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._IterableDataset_len_called \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \\                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m:\u001b[94m671\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_next_data\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 668 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 669 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_next_data\u001b[0m(\u001b[96mself\u001b[0m):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 670 \u001b[0m\u001b[2m│   │   \u001b[0mindex = \u001b[96mself\u001b[0m._next_index()  \u001b[2m# may raise StopIteration\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 671 \u001b[2m│   │   \u001b[0mdata = \u001b[96mself\u001b[0m._dataset_fetcher.fetch(index)  \u001b[2m# may raise StopIteration\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 672 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._pin_memory:                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 673 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = _utils.pin_memory.pin_memory(data, \u001b[96mself\u001b[0m._pin_memory_device)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 674 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m data                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:\u001b[94m58\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mfetch\u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m.dataset, \u001b[33m\"\u001b[0m\u001b[33m__getitems__\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.dataset.__getitems__:         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset.__getitems__(possibly_batched_index)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m58 \u001b[2m│   │   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m59 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m60 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m61 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m:\u001b[94m58\u001b[0m in   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m<listcomp>\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mself\u001b[0m.dataset, \u001b[33m\"\u001b[0m\u001b[33m__getitems__\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.dataset.__getitems__:         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m56 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset.__getitems__(possibly_batched_index)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m57 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m58 \u001b[2m│   │   │   │   \u001b[0mdata = [\u001b[96mself\u001b[0m.dataset[idx] \u001b[94mfor\u001b[0m idx \u001b[95min\u001b[0m possibly_batched_index]                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m59 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m60 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata = \u001b[96mself\u001b[0m.dataset[possibly_batched_index]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m61 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.collate_fn(data)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m:\u001b[94m229\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__getitem__\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[2;33m│   │   │   \u001b[0m\u001b[33mtuple: (sample, target) where target is class_index of the target class.\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m228 \u001b[0m\u001b[2m│   │   \u001b[0mpath, target = \u001b[96mself\u001b[0m.samples[index]                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m229 \u001b[2m│   │   \u001b[0msample = \u001b[96mself\u001b[0m.loader(path)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m230 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.transform \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m231 \u001b[0m\u001b[2m│   │   │   \u001b[0msample = \u001b[96mself\u001b[0m.transform(sample)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m232 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.target_transform \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m:\u001b[94m268\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mdefault_loader\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m265 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m get_image_backend() == \u001b[33m\"\u001b[0m\u001b[33maccimage\u001b[0m\u001b[33m\"\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m266 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m accimage_loader(path)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m267 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m268 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m pil_loader(path)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m269 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m270 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m271 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mImageFolder\u001b[0m(DatasetFolder):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m:\u001b[94m248\u001b[0m in    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpil_loader\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m245 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillo\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m246 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mopen\u001b[0m(path, \u001b[33m\"\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m\"\u001b[0m) \u001b[94mas\u001b[0m f:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   \u001b[0mimg = Image.open(f)                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m248 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m img.convert(\u001b[33m\"\u001b[0m\u001b[33mRGB\u001b[0m\u001b[33m\"\u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m250 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m# TODO: specify the return type\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\PIL\\Image.py\u001b[0m:\u001b[94m921\u001b[0m in \u001b[92mconvert\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 918 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m:returns: An :py:class:`~PIL.Image.Image` object.\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 919 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 920 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 921 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.load()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 922 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 923 \u001b[0m\u001b[2m│   │   \u001b[0mhas_transparency = \u001b[96mself\u001b[0m.info.get(\u001b[33m\"\u001b[0m\u001b[33mtransparency\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 924 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m mode \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.mode == \u001b[33m\"\u001b[0m\u001b[33mP\u001b[0m\u001b[33m\"\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m:\u001b[94m260\u001b[0m in \u001b[92mload\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m257 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   \u001b[0m)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m258 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m259 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mb = b + s                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m260 \u001b[2m│   │   │   │   │   │   │   \u001b[0mn, err_code = decoder.decode(b)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m261 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m n < \u001b[94m0\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m262 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m263 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mb = b[n:]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "autocast = torch.cuda.amp.autocast\n",
    "cast_dtype = None\n",
    "for i,a in enumerate(all_models):\n",
    "    try:\n",
    "        if i <63:\n",
    "            continue\n",
    "       \n",
    "        model, _, preprocess = open_clip.create_model_and_transforms(a[0], pretrained=a[1])\n",
    "        tokenizer = open_clip.get_tokenizer(a[0])\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        dataset=torchvision.datasets.ImageFolder('E:/only_objs',transform=preprocess)\n",
    "        dataloader=torch.utils.data.DataLoader(dataset,shuffle=False,batch_size=64\n",
    "                                        )\n",
    "        \n",
    "\n",
    "\n",
    "        # Example list of texts to encode\n",
    "        \n",
    "        with torch.no_grad():\n",
    "        # Specify batch size\n",
    "            batch_size = 80\n",
    "\n",
    "            # Encode texts in batches\n",
    "            text_features_target = []\n",
    "            for i in range(0, len(all_texts), batch_size):\n",
    "                batch_texts = all_texts[i:i+batch_size]\n",
    "                text = tokenizer(batch_texts)\n",
    "                with torch.no_grad():\n",
    "                    text_features_batch = F.normalize(model.encode_text(text.cuda()))\n",
    "                    # text.cuda()\n",
    "                    # print(text_features_batch.shape)\n",
    "                    text_features_batch=text_features_batch.mean(dim=0)\n",
    "\n",
    "                    # text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "                    text_features_batch /= text_features_batch.norm(dim=-1, keepdim=True)\n",
    "\n",
    "                    # print(text_features_batch.unsqueeze(0).shape)\n",
    "                    # print(text_features_batch.mean(dim=0).shape)\n",
    "                    text_features_target.append(text_features_batch.unsqueeze(0))\n",
    "\n",
    "            # Concatenate text features from batches\n",
    "            text_features_target = torch.cat(text_features_target, dim=0)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            top1, top5, n = 0., 0., 0.\n",
    "            for images, target in dataloader:\n",
    "                images = images.to('cuda')\n",
    "                if cast_dtype is not None:\n",
    "                    images = images.to(dtype=cast_dtype)\n",
    "                target = target.to('cuda')\n",
    "\n",
    "\n",
    "                with autocast():\n",
    "                    # predict\n",
    "                    image_features = model.encode_image(images)\n",
    "                    # image_features = F.normalize(image_features, dim=-1)\n",
    "                    logits = 100. * image_features @ text_features_target.T\n",
    "                # print(image_features.shape)\n",
    "                # measure accuracy\n",
    "                acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
    "                # print(acc1, acc5)\n",
    "                top1 += acc1\n",
    "                top5 += acc5\n",
    "                n += images.size(0)\n",
    "            \n",
    "        top1 = (top1 / n)\n",
    "        top5 = (top5 / n)\n",
    "        row={'model':a[0]+'_'+a[1],'in_dis_Acc_top1':top1,'in_dis_Acc_top5':top5}\n",
    "        print(row)\n",
    "        # df_in = df_in.append(row, ignore_index=True)\n",
    "        # df_in.to_csv('all_model_ood_new_experiment2.csv', index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        row={'model':a[0]+'_'+a[1],'in_dis_Acc_top1':0,'in_dis_Acc_top5':0}\n",
    "        # print(row)\n",
    "        # df_in = df_in.append(row, ignore_index=True)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">timm</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 timm.models()                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'module'</span> object is not callable\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtimm\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 timm.models()                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[32m'module'\u001b[0m object is not callable\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timm\n",
    "timm.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r 'E:/final_dataset/striped ballplayer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510d8ac1378f461db27b89cfb80fdb58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user01\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4087eb3915784a0b94b6fbdc09374cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f05da6369f846979ac2f55eb5cb7503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ip_pytorch_model.bin:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import open_clip\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('xlm-roberta-base-ViT-B-32', pretrained='laion5b_s13b_b90k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtimm\u001b[39;00m\n\u001b[0;32m      3\u001b[0m k\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(all_models[k][\u001b[39m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m model, _, preprocess \u001b[39m=\u001b[39m open_clip\u001b[39m.\u001b[39mcreate_model_and_transforms(all_models[k][\u001b[39m0\u001b[39m], pretrained\u001b[39m=\u001b[39mall_models[k][\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "import timm\n",
    "k=80\n",
    "print(all_models[k][0])\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(all_models[k][0], pretrained=all_models[k][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (0.4.9)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from timm) (0.14.1+cu117)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from timm) (1.13.1+cu117)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from torch>=1.4->timm) (4.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from torchvision->timm) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from torchvision->timm) (9.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from torchvision->timm) (1.24.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from requests->torchvision->timm) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from requests->torchvision->timm) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from requests->torchvision->timm) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages (from requests->torchvision->timm) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\user01\\anaconda3\\envs\\bracs2\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('convnext_base', 'laion400m_s13b_b51k')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models[64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\open_clip\\pretrained.py:338: UserWarning: C:\\Users\\user01/.cache/clip\\vit_l_14-laion400m_e32-3d133497.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
      "  5%|█▉                                  | 90.0M/1.71G [10:45<3:13:41, 139kiB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, _, preprocess \u001b[39m=\u001b[39m open_clip\u001b[39m.\u001b[39;49mcreate_model_and_transforms(\u001b[39m'\u001b[39;49m\u001b[39mViT-L-14\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlaion400m_e32\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\open_clip\\factory.py:292\u001b[0m, in \u001b[0;36mcreate_model_and_transforms\u001b[1;34m(model_name, pretrained, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, pretrained_image, pretrained_hf, image_mean, image_std, aug_cfg, cache_dir, output_dict)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_model_and_transforms\u001b[39m(\n\u001b[0;32m    275\u001b[0m         model_name: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    276\u001b[0m         pretrained: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m         output_dict: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    291\u001b[0m ):\n\u001b[1;32m--> 292\u001b[0m     model \u001b[39m=\u001b[39m create_model(\n\u001b[0;32m    293\u001b[0m         model_name,\n\u001b[0;32m    294\u001b[0m         pretrained,\n\u001b[0;32m    295\u001b[0m         precision\u001b[39m=\u001b[39;49mprecision,\n\u001b[0;32m    296\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    297\u001b[0m         jit\u001b[39m=\u001b[39;49mjit,\n\u001b[0;32m    298\u001b[0m         force_quick_gelu\u001b[39m=\u001b[39;49mforce_quick_gelu,\n\u001b[0;32m    299\u001b[0m         force_custom_text\u001b[39m=\u001b[39;49mforce_custom_text,\n\u001b[0;32m    300\u001b[0m         force_patch_dropout\u001b[39m=\u001b[39;49mforce_patch_dropout,\n\u001b[0;32m    301\u001b[0m         force_image_size\u001b[39m=\u001b[39;49mforce_image_size,\n\u001b[0;32m    302\u001b[0m         pretrained_image\u001b[39m=\u001b[39;49mpretrained_image,\n\u001b[0;32m    303\u001b[0m         pretrained_hf\u001b[39m=\u001b[39;49mpretrained_hf,\n\u001b[0;32m    304\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    305\u001b[0m         output_dict\u001b[39m=\u001b[39;49moutput_dict,\n\u001b[0;32m    306\u001b[0m     )\n\u001b[0;32m    308\u001b[0m     image_mean \u001b[39m=\u001b[39m image_mean \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(model\u001b[39m.\u001b[39mvisual, \u001b[39m'\u001b[39m\u001b[39mimage_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    309\u001b[0m     image_std \u001b[39m=\u001b[39m image_std \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(model\u001b[39m.\u001b[39mvisual, \u001b[39m'\u001b[39m\u001b[39mimage_std\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\open_clip\\factory.py:201\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(model_name, pretrained, precision, device, jit, force_quick_gelu, force_custom_text, force_patch_dropout, force_image_size, pretrained_image, pretrained_hf, cache_dir, output_dict, require_pretrained)\u001b[0m\n\u001b[0;32m    199\u001b[0m pretrained_cfg \u001b[39m=\u001b[39m get_pretrained_cfg(model_name, pretrained)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m pretrained_cfg:\n\u001b[1;32m--> 201\u001b[0m     checkpoint_path \u001b[39m=\u001b[39m download_pretrained(pretrained_cfg, cache_dir\u001b[39m=\u001b[39;49mcache_dir)\n\u001b[0;32m    202\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(pretrained):\n\u001b[0;32m    203\u001b[0m     checkpoint_path \u001b[39m=\u001b[39m pretrained\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\open_clip\\pretrained.py:393\u001b[0m, in \u001b[0;36mdownload_pretrained\u001b[1;34m(cfg, force_hf_hub, cache_dir)\u001b[0m\n\u001b[0;32m    390\u001b[0m     download_url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    392\u001b[0m \u001b[39mif\u001b[39;00m download_url:\n\u001b[1;32m--> 393\u001b[0m     target \u001b[39m=\u001b[39m download_pretrained_from_url(download_url, cache_dir\u001b[39m=\u001b[39;49mcache_dir)\n\u001b[0;32m    394\u001b[0m \u001b[39melif\u001b[39;00m download_hf_hub:\n\u001b[0;32m    395\u001b[0m     has_hf_hub(\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\site-packages\\open_clip\\pretrained.py:345\u001b[0m, in \u001b[0;36mdownload_pretrained_from_url\u001b[1;34m(url, cache_dir)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(total\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(source\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Length\u001b[39m\u001b[39m\"\u001b[39m)), ncols\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39miB\u001b[39m\u001b[39m'\u001b[39m, unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m loop:\n\u001b[0;32m    344\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m         buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mread(\u001b[39m8192\u001b[39;49m)\n\u001b[0;32m    346\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m buffer:\n\u001b[0;32m    347\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    464\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1243\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\user01\\anaconda3\\envs\\BRACS2\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1101\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', pretrained='laion400m_e32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BRACS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
